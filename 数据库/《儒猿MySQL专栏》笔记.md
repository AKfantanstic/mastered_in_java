生产经验:

* Java应用系统部署在4核8G机器上，每秒可以抗500左右并发量。
* 一般8核16G的机器部署MySQL数据库，每秒可以抗1、2K并发
* 对于16核32G的机器部署MySQL数据库，每秒可以抗2、3k并发，3-4k并发



undo log、redo log是innodb存储引擎层的日志，binlog是mysql的server层日志

redo log是一种物理性质的重做日志，记录的是基于磁盘上存储的数据页所做的修改，例如对磁盘中存储的某个数据页中的什么记录，做了什么修改

binlog叫做归档日志，记录的是逻辑日志，都是sql

## "update user set name = 'XXX' where id = 10" 的更新过程？

进入事务的最终提交阶段，会把本次更新对应的binlog文件名和本次更新内容记在binlog文件中的位置，都写入到redo log中，同时在redo log文件中写入一个commit标记，整个事务完成。commit标记用于保持redo log和binlog的一致性，假如刚刚将redolog写入磁盘文件，mysql宕机了，此时机器恢复后，由于redo log中没有commit标记，所以mysql判定此次事务不成功。假如将binlog写入磁盘了，然后mysql宕机了，此时同样会因为redo log中没有commit标记，认定此次事务不成功，必须是在redo log中写入commit标记后，才算此时事务提交成功，这时redolog 中有本次更新对应的日志，binlog中也有本次更新对应的日志，这时redo log和binlog是完全一致的。最后由后台IO线程将脏页刷回磁盘。

## redo log buffer对应的redo log的3种刷盘策略

通过mysql配置中的innodb_flush_log_at_trx_commit参数来配置刷盘策略:

1. 参数为0: 提交事务时不会将redo log buffer里的数据写入磁盘。**此时宕机数据丢失**
2. 参数为1：提交事务之前必须保证将redo log buffer里的数据写入磁盘。
3. 参数为2:  提交事务之前仅将redo log buffer中数据写入磁盘文件对应的osCache中，后续由操作系统决定什么时候写入磁盘文件。**宕机后数据可能丢失**

通常必须设置为1，也就是说要提交事务时redo log必须刷入磁盘文件里，因为对于数据库这样的严格系统，必须要保证事务提交后，数据绝不会丢失。

## binlog的刷盘策略？
用sync_binlog参数来控制binlog的刷盘策略。
* 默认值是0：把binlog写入osCache而不是直接写入磁盘文件中。此时宕机则os cache中binlog会丢失，可能会造成事务提交成功但binlog丢失
* 参数为1: 强制在事务提交时将binlog写入磁盘文件里。这样即使提交事务后机器宕机，binlog也不会丢。

## 为什么要在redolog中写入commit标记?

用来保证redolog和binlog的强一致性。写入redo log，写入binlog，把binlog文件名和本次事务记录在binlog的位置写入redolog，最后在redo log中写入commit标记，其中任何一个中间步骤出错，事务都是提交失败的，只有写入commit标记了，才算事务提交成功，这就是mysql的innoDb存储引擎定的规则

# 数据库压测

## 需要关注的相关性能指标:

IO相关:
(1)IOPS:指的是机器随机IO并发处理能力，比如200 IOPS 意思就是说每秒可以执行200个随机IO读写请求。当在内存bufferPool中写入脏数据后，需要后台IO线程在机器空闲时刷回到磁盘，这是一个随机IO的过程。如果IOPS过低，会导致内存里脏数据刷回磁盘的效率太低
(2)吞吐量:指的是机器磁盘每秒可以读写多少字节
当执行sql提交事务时需要将大量redo log等日志写入磁盘。写入redolog一般是一行一行顺序写入，不会进行随机读写，一般普通磁盘顺序写吞吐量可达到每秒200MB
，对于承载高并发来说，磁盘吞吐量通常不是瓶颈
(3)latency:指的是向磁盘写入一条数据的延迟。当执行sql和提交事务时，需要将redo log顺序写到磁盘，如果写入延迟过高会影响数据库的sql执行性能。写入延迟越低，执行sql的事务的速度就越快，数据库性能就越高
(4)CPU负载:压测中如果CPU负载特别高，就说明已经到达瓶颈，不能继续压测了
(5)网络负载:关注每秒钟网卡会输入多少MB数据，会输出多少MB数据，当到达网络带宽最大值时说明已经出现瓶颈了，就不能再继续压测了
(6)内存负载:如果内存占用过高，也说明不能继续压测了

## 数据库压测工具 sysbench 使用方法
```
使用如下命令设置yum repo仓库，然后使用yum来安装sysbench
curl -s https://packagecloud.io/install/repositories/akopytov/sysbench/script.rpm.sh|sudo bash
sudo yum -y install sysbench
sysbench --version  
看到sysbench版本号说明安装成功

然后在数据库建好测试库名字叫test_db,然后创建测试账号，然后基于sysbench构建20个测试表，每个表100万条数据，使用10个并发线程对数据库发起访问，连续访问300秒，也就是压测5分钟。
先基于sysbench构造测试表和测试数据:
sysbench --db-driver=mysql --time=300 --threads=10 --report-interval=1 --mysql-host=192.168.11.113 --mysql-port=3306 --mysql-user=root --mysql-password=123456 --mysql-db=test_db --tables=20 --table_size=1000000 oltp_read_write --db-ps-mode=disable prepare

(1)--db-driver=mysql: 基于mysql驱动去连接mysql数据库，如果是oracle、sqlServer可以更换
(2)--time: 连续压测时间，单位秒
(3)--threads=10: 10个线程并发访问
(4)--report-interval=1: 每隔1秒输出压测情况
(5)--mysql-host=127.0.0.1 --mysql-port=3306 --mysql-user=test_user --mysql-password=test_user:指定mysql连接相关信息
(6)--mysql-db=test_db --tables=20 --table_size=1000000: 指定压测数据库，构造20个测试表，每个表100万条测试数据
(7)oltp_read_write: 执行oltp数据库的读写测试
(8)--db-ps-mode=disable: 禁用ps模式
(9)prepare: 按照上面的命令去构造测试数据
   run:运行压测
   cleanup:清理测试数据
   
测试数据库综合读写TPS，使用oltp_read_write模式:
sysbench --db-driver=mysql --time=300 --threads=20 --report-interval=1 --mysql-host=192.168.11.113 --mysql-port=3306 --mysql-user=root --mysql-password=123456 --mysql-db=test_db --tables=20 --table_size=1000000 oltp_read_write --db-ps-mode=disable run

测试数据库的只读性能，使用oltp_read_only模式(将oltp_read_write改为oltp_read_only)

测试数据库的删除性能，使用oltp_delete模式

测试数据库的更新索引字段性能，使用oltp_update_index模式

测试数据库的更新非索引字段的性能，使用oltp_update_non_index模式

测试数据库的写入性能，使用oltp_write_only模式

[ 116s ] thds: 20 tps: 340.03 qps: 6809.60 (r/w/o: 4760.42/1369.12/680.06) lat (ms,95%): 125.52 err/s: 0.00 reconn/s: 0.00
每秒压测报告解读:
(1)thds:20,压测线程数
(2)tps:340.03，每秒执行340.03个事务
(3)qps:6809.60，每秒执行6809.60个请求
(4)r/w/o:760.42/1369.12/680.06 : 每秒6809.60个请求中，有760.42个读请求，1369.12个写请求，680.06个其他请求。也就是对QPS的拆解
(5)lat(ms,95%):125.52 :95%请求的延迟在125.52毫秒以下
(6)err/s:0.00 reconn/s:0.00 :每秒有0个请求失败，发生了0次网络重连

总压测报告:
SQL statistics:
    queries performed:
        read(压测期间执行的总读请求数): 1275694
        write(总写请求数):            364484
        other(总其他请求数):          182242
        total(总请求数):              1822420
    transactions:                        91121  (303.60 per sec.)
    queries:                             1822420 (6072.00 per sec.)
    ignored errors:                      0      (0.00 per sec.)
    reconnects:                          0      (0.00 per sec.)

General statistics:
    total time:                          300.1328s
    total number of events(总执行事务数):  91121

Latency (ms):
         min(请求最小延迟):  12.34
         avg(请求平均延迟):  65.85
         max(请求最大延迟):  1494.97
         95th percentile(95%请求延迟时间): 123.28
         sum:  6000298.15

Threads fairness:
    events (avg/stddev):           4556.0500/20.80
    execution time (avg/stddev):   300.0149/0.03
```























# Buffer Pool:

本质就是数据库中一个基于内存的组件，核心是通过使用内存而不是直接使用磁盘来提高访问速度。Java系统对数据库执行增删改查请求主要就是对这个内存组件中的缓存数据进行访问的

### 如何配置buffer pool大小？
bufferPool 默认大小为128MB，偏小，对于16核32G机器，可以给BufferPool分配个2GB内存,通过修改配置参数:

```shell
[server]
innodb_buffer_pool_size=2147483648
```



数据页是mysql中抽象出来的数据单位，mysql提供给用户的数据模型是表+字段+行记录的概念
，我们用户和开发者也都很熟悉知道数据库里有一个一个的表，一个表有很多字段，一个表中有很多条数据，每行数据都有自己的字段值。但是在mysql底层物理结构是以数据页为单位的，它把很多行数据放在了一个数据页里。也就是说磁盘文件中有很多数据页，每格数据页存放了很多行数据，所以bufferPool中存放的是一个一个的数据页

















bufferPool内部结构:buffer_pool中包含多个缓存页，同时每个缓存页还有一个描述数据。当数据库启动时，会按照bufferPool的大小再稍微加大一点去向操作系统申请一块内存区域，作为bufferPool内存区域。然后按照默认缓存页的16KB大小以及800个字节左右的描述数据大小，将整个bufferPool划分成一个一个的缓存页和一个一个的缓存页对应的描述数据。每个描述数据块都是free链表的一个节点，free链表是一个双向链表




















## 如何查询一个数据页是否在bufferPool中呢？
数据库中有一张hash表，使用表空间+数据页号作为key，缓存页的地址作为value。当要使用一个数据页时，通过“表空间号+数据页号”作为key去hash表中查询，如果value为空说明缓存页不存在，则需要从磁盘中读取数据页到缓存页中

## 如果bufferPool中的缓存页不够了怎么办？
bufferPool中维护了一个由缓存页的描述数据块作为结点的LRU链表，最近被访问过的数据块一定在LRU链表的头部。当缓存页满了时，就会找出最近最少被访问的缓存页，将这个缓存页刷入磁盘

MySQL使用磁盘存储数据是以页为单位的，BufferPool以页为单位从磁盘中加载数据，叫做缓存页，每个bufferPool中的页会和磁盘上的页一一对应起来，而每一页可能会记录好几行数据，默认情况下一页数据大小是16KB。每页的描述数据大概占页大小的5%用于存储缓存页信息
<bufferPool从磁盘加载页的图>

### 数据库启动时是如何初始化BufferPool的？
数据库启动时，按照配置中的bufferPool大小去找操作系统申请一块内存作为bufferPool缓存区域，申请完毕后按照设定的缓存页大小(默认16KB)以及800字节左右的描述数据大小，把bufferPool划分成一个一个的缓存页和对应的描述数据。划分完成后，缓存页都是空的，只有java系统发起增删改查请求时才会把数据以页为单位从磁盘中读取出来放入bufferPool的缓存页中。
《画图》

### 怎么能知道bufferPool中哪些缓存页是空闲的？
bufferPool中用一个双向链表来管理所有空闲的数据页，叫做free链表，链表中的每个节点都是一个空闲缓存页的描述数据(只要有一个缓存页是空闲的，它的描述数据就会被放到free链表中，数据库刚启动时所有的缓存页都是空闲的，此时所有缓存页的描述数据都在free链表中)，free链表中还有一个基础节点，里面存了free链表的头节点地址和尾节点地址还有free链表中当前还有多少个节点，但这个节点不属于bufferPool
《画图》

### 如何将磁盘上的页读取到bufferPool的缓存页中去？
先从free链表中取一个描述数据块，根据描述数据节点取到对应的空闲缓存页，然后把磁盘上的数据页读取到这个空闲缓存页里，然后把如数据页所属表空间等页相关描述数据写入描述数据块，然后从free链表中去除这个描述数据块就可以了

### 怎么知道数据页有没有被缓存呢？
当java系统向数据库发起增删改查请求时，一定是先判断数据页有没有被缓存，如果没有缓存就走上面的流程从磁盘中加载到bufferPool，如果数据页已被缓存则直接使用。
在数据库内部是使用一个哈希表，以表空间+数据页号为key，缓存数据页内存地址为value，来记录数据页是否被缓存。
当java系统要使用一个数据页时，先以"表空间号+数据页号"作为key去哈希表中查询页是否存在，如果不存在则从磁盘加载，然后在哈希表中写入一个key-value对，key就是表空间号+数据页号，value就是缓存页的内存地址，如果存在则说明数据页已缓存可以直接访问

### 什么原因会造成 bufferPool 中产生内存碎片？
由于bufferPool大小可以自定义，所以划分完缓存页和对应的描述数据后，还剩一点内存，这一点内存无法容纳一个缓存页，只能放着不能用，这点内存就是内存碎片。

### 数据库是如何减少bufferPool的内存碎片的？
如果数据库在给bufferPool划分缓存页时，是东一块西一块的，就会导致缓存页之间产生内存空洞，形成大量内存碎片。
实际上数据库在给bufferPool划分缓存页时是连续分配，会让所有的缓存页和描述数据块都紧密的挨在一起，这样就尽量减少了内存碎片

### 什么是脏页？
Java系统发送给数据库的增删改查请求，最终会在bufferPool中被执行，而磁盘上数据并没有变，这时bufferPool中被修改的缓存页就叫脏页

### 怎么知道哪些缓存页是脏页呢？
BufferPool中使用一个叫做flush链表的双向链表来记录bufferPool中的脏页，凡是被修改过的缓存页，都会把它的描述数据块加入到flush链表中，flush链表结构跟free链表结构几乎一样。flush就是刷脏页的意思，后续是要把脏页flush到磁盘上的

### 如果bufferPool满了，要在bufferPool中淘汰一些缓存页，该淘汰谁？
bufferPool内部使用了一个LRU链表(least recently used,最近最少使用)来记录哪些缓存页是最近最少被使用的。所有从磁盘加载的缓存页的描述数据块都会被这个LRU链表记录，当某个缓存页被访问(查询或修改),就会把这个缓存页的描述数据块挪到LRU链表的头部，也就是说最近被访问的缓存页一定在LRU链表的头部，而尾部保存的就是最近最少被访问的数据页。当bufferPool满了时，就会从LRU链表的尾部开始找到一个缓存页，把缓存页的数据flush到磁盘，然后将数据从缓存页中清空，最后把正在请求的数据从磁盘加载到这个缓存页从中。

### 缓存命中率
在100次请求中，有30次是在查询和修改缓存页中的数据，那么缓存命中率为30%

### 在 SQL 语句中用到的是表和行的概念，而数据库内部是使用表空间和数据页，两者的关系是什么呢？
表和行是逻辑概念，逻辑层面无需关心物理层面的实现。表空间、数据页就属于物理概念，在物理层面上，一个表里的数据都是放在一个表空间中，表空间由一堆磁盘上的数据文件组成，而数据文件是由一个一个的数据页组成的。

### 说下 Mysql 的预读机制？
当从磁盘加载一个数据页时，会连带着把跟它相邻的数据页也加载到 bufferPool 中
### 哪些情况下会触发mysql的预读机制？
(1)mysql配置中有一个参数:"innodb_read_ahead_threshold"，默认值为56，意思是如果顺序访问了一个区里的多个数据页
，访问的数据页数量超过这个阈值，就会触发预读机制将下一个相邻区中的所有数据页全部加载到bufferPool里
(2)如果bufferPool里缓存了一个区里的连续13个数据页，而且这些数据页被频繁访问，就会触发预读机制，将整个区的其他数据页都加载到bufferPool里。
这个机制通过配置中参数"innodb_random_read_ahead"控制，默认是off
### 为什么mysql要设计这个预读机制？

### MySQL的bufferPool中的LRU链表结构:
由于简单LRU链表在mysql预读和全表查询两种情况下存在的缓存页热度失真的情况，mysql在设计lru链表时采用的是
冷热数据分离的思想。整个链表分为两部分，一部分是冷数据，一部分是热数据，冷数据比例由参数"innodb_old_blocks_pct"控制，默认是37，也就是说冷数据
占37%。第一次从磁盘加载到bufferPool的缓存页会被放在冷数据区的链表头部

### 什么时候会将冷数据区的缓存页移动到热数据区？
mysql设定了一个规则，一个数据页从磁盘加载到bufferPool 1s 后被访问才会被移动到热数据区链表头，1s内的还留在冷数据区。
可以修改mysql配置参数"innodb_old_blocks_time"默认值为1000，也就是1000毫秒。

### 为什么要使用基于冷热数据分离的LRU链表？主要是为了解决什么问题？
为了解决使用普通LRU链表时在预读机制和全表查询场景造成的缓存热度失真。
这样预读或者全表扫描加载的数据页，大部分会在1s内访问后之后再也不访问了，这种缓存页会留在冷数据区，而频繁访问的
缓存页在热数据区中。当淘汰缓存时，就会优先淘汰冷数据区尾部的缓存页，避免了可能会把热数据淘汰掉

### LRu链表尾部的缓存页，是如何淘汰他们刷入磁盘的？
由后台线程在mysql不忙的时候去把flush链表的缓存页都刷入磁盘

## Mysql是如何把lru链表的热数据区优化到极致的？
按之前的规则，在从磁盘加载到冷数据区，只有1秒后被访问的数据，才会被移动到热数据区的链表头。在热数据区中的数据，如果每次一个缓存页被访问都需要移动到热数据区的链表头，会造成频繁移动，会影响性能。
所以mysql把热数据区分为两部分，前1/4和后3/4。前1/4的缓存页被访问是不会被移动到链表头的，只有后3/4的缓存页被访问才会被移动到链表头，这样就尽可能的减少了链表中的节点移动了。

### bufferPool在访问的时候需要加锁吗？
必然需要。由于bufferPool的本质是一块内存数据结构，由一大堆的缓存页和描述数据组成，然后加上各种链表(free、flush、lru)来辅助他的运行。
但是当mysql收到请求时是用多线程处理的，所以是多线程并发访问BufferPool必然需要加锁。先让一个线程加载数据页到缓存页，然后
更新free链表，更新lru链表，然后释放锁，接着才轮到下一个线程来执行一系列操作

### 多线程并发访问bufferPool并且还需要加锁，数据库的性能还好吗？
即使就一个bufferPool，即使多个线程排队加锁来串行执行，由于操作发生在内存里，并且更新free、flush、lru链表等都是基于基本都是微秒级别的，所以性能也差不了哪去。

### 多线程并发访问bufferPool并且还需要加锁，数据库的性能还好吗？
即使就一个bufferPool，即使多个线程排队加锁来串行执行，由于操作发生在内存里，并且更新free、flush、lru链表等都是基于链表进行一些指针操作，基本都是微秒级别的，所以性能也差不了哪去。
但是由于有的线程拿到锁后，会需要从磁盘中读取数据页到缓存页中，这里发生了磁盘io，比较耗时，自然会影响性能。

### 如何改进bufferPool中并发加锁中发生IO导致的性能下降？
生产环境可以设置多个bufferPool来优化整体并发能力。
Mysql默认规则是如果给bufferPool分配的内存小于1GB，那么最多只会分配给1个bufferPool。如果mysql使用的机器内存很大，必然会给bufferPool分配较大的内存，比如给BufferPool分配8G内存，此时可以设置多个BufferPool，每个bufferPool设置为2g内存
```
[server]
innodb_buffer_pool_size=8589934592
innodb_buffer_pool_instances=4
```
设置后mysql运行时有4个bufferPool，每个bufferPool只管理一部分的缓存页和描述数据块，可以使用多个线程来并发访问不同的bufferPool，因为多个线程在不同的bufferPool中加锁然后执行自己的操作，可以使mysql性能成倍提升。因此在生产环境通过设置多个bufferPool来优化高并发访问性能是mysql一个很重要的优化技巧

### bufferPool这种大块头可以在运行期间动态调整大小吗？
可以。mysql把bufferPool实现为由很多chunk组成，chunk大小由配置参数"innodb_buffer_pool_chunk_size"控制，默认值为128MB。一个2GB的bufferPool由16个128MB的chunk组成，每个bufferPool里的多个chunk共享一套free、flush、lru链表。有了这套chunk机制，就可以动态调整bufferPool大小了。当要扩大内存时，只需要申请一系列大小为128MB的chunk就可以了，只要每个chunk是连续的128MB内存即可，然后把申请到的chunk分配给bufferPool































### 我们写入数据库的一行数据在磁盘上是如何存储的？
由于存储数据要节约空间，所以不能使用java序列化对象的方式，因此在mysql的innodb存储引擎中是把很多行数据都紧紧挨在一起的方式存储的，这里引入了一个数据页的概念，也就是把数据组织成一页一页的概念，每页16kb，每次从磁盘加载数据到内存是至少加载一页数据进去的，甚至是多页数据
变长字段是如何存储的？
null值是如何存储的？

### 数据库返回“too many connections”，如何定位？
返回"too many connection"表示数据库的连接池里已经有太多连接了，无法继续创建新连接了。数据库内部有一个连接池，java系统里的数据库连接池里的连接和数据库内部连接池的连接一一对应。

* 实际案例排查思路：64g大内存机器上部署mysql，有两个java实例连接mysql，每个java实例配置的数据库连接池大小为200，当两台java实例启动时报“too many connections”，说明数据库当前建立的连接少于400个，检查my.cnf文件中配置的max connections为800，然后登录到mysql，使用命令“show variables like 'max_connections'”显示当前连接数为214个，这是由于底层linux操作系统把每个进程可以打开的文件句柄数限制为了1024额所以导致mysql最大连接数为214。

* 解决方法：在linux上输入：

  ```
  ulimit -HSn 65535  修改每个进程可以打开的最大文件句柄数为65535，
  ```

  然后使用下面命令查看是否修改成功：

  ```
  cat /etc/security/limits.conf
  cat /etc/rc.local
  ```

  查看是否修改成功查看是否修改成功


### redo log存在的意义？
当事务提交成功时，mysql绝对会保证这个事务所做的修改都记录在了redo log中，才会给你返回成功，这时即使mysql宕机也不怕了。mysql宕机重启后会根据redo log中记录的事务所做过的修改，重新从磁盘加载然后在bufferpool里都执行一遍，就可以恢复当时事务对缓存页做的修改了，然后再找时机把缓存页刷入磁盘

### redo log长什么样？
本质上就是记录的在某个表空间的某个数据页的某个偏移量修改了几个字节的值。
实际记录的是表空间号＋数据页号＋偏移量＋修改几个字节的值＋具体的值

### redo log是直接一条一条写入文件的吗？(redo log写磁盘的过程)

redo log不是一条一条直接往磁盘里写的，

之前了解过mysql的innodb引擎存储数据并不是单行存储的，而是以数据页为最小单位来存储的。

同样redo log也不是由一行一行的数据组成的，redo log是以redo log block为最小单位来存储的，一个redo log block可能记录了多个单行日志

redo log的确是存在磁盘上的文件，这个文件是由很多个redo log block 组成的，

如果依次在磁盘文件的末尾追加不停的写字节数据，就是磁盘顺序写。如果在多个文件中找出一个文件再修改这个文件的几个字节的内容，就是磁盘随机写

### redo log是如何通过redo log buffer这个内存缓冲数据结构写入到磁盘文件的

首先，一组事务里的多条redo log是作为一个redo log group存在的，先暂存在内存缓冲中，等事务执行完成时，把整个redo log group写入内存的一块叫做redo log buffer的内存区域，然后才会把redo log buffer中的redo log block写入redo log文件的。这个区域是mysql启动时向操作系统申请的一块连续内存。和bufferPool类似，mysql会把redo log buffer划分成很多个空的 redo log block。redo log buffer默认是16MB，也可以通过参数“innodb_log_buffer_size”更改。如果redo log buffer里所有的block都写满了，就会强制将block刷入磁盘中。而如果一个事务比较大， 所形成的redo log超过了一块block，是可以存放在两个block中的。

### redo log buffer中的redo log block到底什么时候可以写入磁盘？

(1)如果写入redo log buffer的日志占据redo log buffer总容量的一半，也就是超过8MB，就会把他们刷入磁盘。这种场景在mysql瞬间执行大量高并发sql时可能会出现，1s内产生超过8MB的redo log，此时会立即把redo log刷入磁盘

(2)一个事务提交时，必须把事务的redo log所在的redo log block刷入磁盘。这样才能保证事务提交后事务所修改的数据不会丢失，宕机后可以根据redo log来重做恢复(redo log写入磁盘时是先写入操作系统的os cache中，再写磁盘的，要想保证数据绝对不丢，需要配置一个参数，在提交事务把redo log刷入磁盘文件的os cache后，还得强行从os cache刷入物理磁盘才能保证绝对不丢。)

(3)后台线程定时刷新。后台有一个线程会每隔1s把redo logbuffer里的redo log block刷入磁盘。一般都会通过第二个场景刷入磁盘，只是一种补偿措施

(4)mysql关闭时，redo log block会全部刷入磁盘

### redo log写满了怎么办？

redo log的存放目录可以通过参数"innodb_log_group_home_dir"来指定。通过参数"innodb_log_files_in_group"可以指定日志文件数量，默认有两个redo log文件，分别为ib_logfile0 和ib_logfile1。通过参数“innodb_log_file_size”来指定每个redo log文件的大小，默认是48MB。先写第一个文件，写满了再写第二个，如果第二个也写满了，就继续写第一个来覆盖第一个日志文件原有的redo log。96MB足够存上百万条redo log了

### undo log也就是回滚日志有什么作用？undo log的工作原理是什么？

undo log用于事务回滚的场景。undo log记录的是当前事务所有执行操作的反操作，事务操作无非是增删改，那undo log就记录了这三种操作各自的反操作。如果事务执行了一个insert操作，undo log里就记录一个delete刚刚insert的记录的主键的操作，如果是delete操作，则undo log就记录insert语句；如果是update操作，undo log就把原值记录下来。

### insert语句的undo log回滚日志长什么样？

==insert语句的undolog类型为TRX_UNDO_insert_rec==

一条insert语句的undo log语句是这样组成的:undo log日志开始位置 | 主键<列长度，列值> | 表id | undo log日志编号 | undo log日志类型 | undo log日志结束位置

### 已经讲完了MySQL的BufferPool机制、redo Log机制、undo log机制，应该对平时执行增删改查语句的实现原理有一定的深入理解

(数据库中多个事务并发执行可能带来的问题)多个事务对缓存页里的同一条数据进行更新或者查询，会产生哪些问题呢？脏写、脏读、不可重复读、幻读

脏写:两个事务在没提交的情况下，都修改同一条数据，结果一个事务回滚了，把另一个事务修改的值给撤销了

脏读:一个事务修改了一条数据还没提交呢，就被另一个事务读到了修改的数据，然后第一个事务回滚了导致第二个事务读到了脏数据 

无论是脏读还是脏写，原因都是一个事务读取或者更新了另一个事务还没有提交的数据造成的

不可重复读:一个事务两次查询同一条数据得到的查询结果不同，也就是说在一个事务的两个查询中中间穿插了另一个事务对记录修改后成功提交。不可重复读不算什么大问题，到底有没有不良影响取决于使用场景能不能接受，但在sql标准中，也就是在数据库实现的角度不可重复读是被定义为一种数据库的问题

幻读:就是幻行，两次范围查询中后一次查询读到了比第一次查询多的记录

### SQL标准中对事务的4个隔离级别是如何规定的？

针对数据库的多事务并发带来的几个问题，所以sql标准规定了事务的4种隔离级别来解决这些问题。

* 第一个读未提交隔离级别。不允许发生脏写，也就是说不允许两个事务在没提交的情况下去更新同一行数据。允许发生脏读、不可重复读、幻读
* 第二个是读已提交级别。不允许发生脏写和脏读，由于其他事务未提交的记录是无法被另一个事务读到的，所以就避免了脏读。同时允许发生不可重复读和幻读
* 第三个是可重复读级别。不允许发生脏写、脏读、不可重复读。由于一个事务的多次查询即使数据被其他事务修改了，他也是读不到的，所以查询结果始终没有变化，因此避免了脏写、脏读、不可重复读
* 第四个是串行化级别。不允许事务并发执行，只能一个一个排队执行，所以能避免一切并发带来的问题

### MySQL是如何支持SQL标准中的4种隔离级别的？

mysql支持sql标准中的4种隔离级别，除此之外，mysql默认事务隔离级别为可重复读，sql标准下这个隔离级别是可以发生幻读的，而mysql对可重复读隔离级别的实现能做到避免幻读！总之，在mysql可重复读隔离级别下，能做到事务之间互相完全不影响

### 理解MVCC机制的前奏，undo log版本链是什么？

mysql的默认隔离级别可重复读能做到多个事务并发执行之间互不影响，依靠的就是经典的MVCC多版本并发控制机制来做到的。而mvcc机制是由undo log版本链和readView来实现的。

undo log版本链:表中的每条数据都有两个隐藏字段，一个是trx_id，表示最近一次更新这条数据的事务id；一个是roll_pointer，记录的是这条数据在被trx_id这个事务更新之前的undo log指针。

因为mysql数据库已经根据sql标准去在任何级别下避免了脏写，所以多个事务是串行修改一行数据的，并且修改时会更新隐藏字段trx_id和roll_pointer

#### 基于undo log版本链是如何实现readView机制的？

readView，就是执行事务时，会生成一个readView，读视图，比较关键的参数有4个:

* m_ids:此时有哪些事务正在执行还没有提交
* min_trx_id:m_ids里的最小值
* max_trx_id:mysql下一个要生成的事务id，也就是最大事务id
* creator_trx_id:当前事务的id

通过记录undo log多版本链条，再加上事务开启时生成的一个readView，然后事务中的查询就根据readView进行判断，去选择读取哪个版本的数据。这套机制能保证当前事务只能读到事务开启前已经提交的事务更新的值，还有本事务更新的值。 当本事务开启后，其他事务更新了值无论是否已提交，本事务都不会读到修改的值。 通过这套机制实现了多个事务并发执行时的数据隔离

#### 读已提交级别是如何基于readView机制实现的？

读已提交隔离级别的意思就是，在本事务运行期间，只要其他事务修改后提交了，那本事务就可以读取其他事务所提交的数据。所以这样会发生不可重复读、幻读问题。

所以对于读已提交级别，是每次发起新查询都会重新生成一个readView

#### 可重复读级别是如何基于readView机制实现的？

事务开启后，生成一个readView，然后在整个事务查询过程中都使用这一个readView去处理数据可见性

#### 梳理:MySQL中的多事务并发运行的隔离原理，也就是MVCC机制的运行过程

用undo log版本链，加上readView规则，来判断数据的可见性，主要是readView在读已提交和可重复读两个级别下的判断条件

#### 多个事务并发更新同一行数据，数据库是怎么避免脏写的？

简单说，脏写是依靠锁机制把并发更新做串行化处理，避免并发更新。当事务A要对一行数据更新时，先检查下是否有其他事务对这行数据加了锁，如果没有则会创建一个锁，锁里面包含本事务的trx_id和等待状态false(已经获取锁)，然后把这把锁和这行数据做关联(在内存中)。这是事务B要修改这行记录检查是否有锁，发现这行数据已被加锁，事务B也生成一个锁数据结构，等待状态为true。当A更新完成后，会把锁释放然后去找是否有其他事务对这行数据加锁，发现了事务B加的锁，然后把事务B的锁的等待状态改为false，然后唤醒B继续执行。

#### MySQL中的共享锁和独占锁

多个事务并发更新同一行数据时加的是行级别独占锁。

mysql也支持共享锁，语法为:select * from table lock in share mode

mysql也支持独占锁，语法为:select * from table for update

* 共享锁和共享锁不互斥，可以同时加。
* 共享锁和独占锁互斥，不能同时加。
* 独占锁和独占锁互斥，不能同时加

一般开发业务系统时， 很少在数据库去加共享锁、行锁，而是用基于zookeeper/redis的分布式锁来控制业务的锁逻辑

#### 数据库中哪些操作会导致在表级别加锁？



#### 案例实战:线上数据库不定时的性能抖动优化

* 不是之前讲过的数据库锂电池充放电问题
* 第一个原因可能是bufferPool满了，而执行的是查询语句，需要将大量数据缓存到bufferPool中，导致bufferpool中大量的脏页需要刷入磁盘，刷磁盘太慢了导致这期间的查询语句执行很慢造成性能抖动
* 第二个原因可能是redo log日志文件全部被写满了，这时候也会触发刷脏页。因为需要回到第一个redo log文件开始覆盖写，而在覆盖写之前需要把第一个redo log里的缓存页刷入磁盘

上面两个场景都是由于刷脏页导致的性能抖动。解决方法就是尽可能优化mysql参数。比较核心的两个点: 第一是降低缓存页刷入磁盘的频率，第二是提高缓存页刷入磁盘的速度

降低刷入频率:部署数据库的机器使用ssd固态硬盘，因为随机io很高。使用固态硬盘后还需要设置参数"innodb_io_capacity"来告诉数据库使用多大的IO速率把缓存页刷入磁盘。还有一个参数是"innodb_flush_neighbors"表示在将缓存刷入磁盘时，可能会把缓存页相邻的其他缓存页也刷入磁盘，但是这样会导致flush时需要刷新的缓存页过多，如果使用SSD，可以把"innodb_flush_neighbors"参数设置为0，表示禁止刷相邻缓存页，这样就可以减少每次刷盘的缓存页了

#### 磁盘数据页的存储结构是什么样的？

数据页之间是组成双向链表的，数据页内部的数据行是组成单向链表的，而且数据行是根据主键大小从小到大排序的

数据库最终所有的数据都是存放在磁盘上的文件里的，而在文件中存放的物理格式是数据页，大量的数据页是按顺序一页一页存放的，两个相邻的数据页之间采用双向链表的格式互相引用，而每个数据页在文件中其实就是一段数据，"Datapage:xx=xx,linked"，数据页里包含两个指针，一个指向自己上一个数据页的物理地址，一个指向自己下一个数据页的物理地址。然后每个数据页内部会存储一行一行的数据，每行数据都会按照主键大小排序存储，同时每一行数据都有指针指向下一行数据的位置，组成单向链表

#### 查询一条数据的过程？

* 根据主键查询: 每个数据页里都有一个页目录，存放这个页里每个主键和所在槽位的映射关系。
  每张表都有一个主键索引，也叫主键目录，是由数据页号和最小主键值组成的。如果是根据主键查询一条数据，则只需要在主键目录里通过二分查找来找到对应的数据页，就可以在数据页中找到要的数据了
* 根据非主键且没有索引的字段查询: 由于无法利用页目录来进行二分查找，所以无论怎么查找数据都是一个全表扫描的过程，只能。最坏情况下需要把所有数据页里的每条数据都得遍历一遍才能要找到想要的那条数据，这就是全表扫描

#### 什么情况下会发生页分裂？

在不停往表中插入数据时，会增加一个一个的数据页，如果主键不是自增的，就会有一个数据行的挪动过程，核心目的是为了保证下一个数据页里的主键值都比上一个数据页的主键值大，这个调整叫做页分裂

#### 索引的页存储物理结构是如何用B+树实现的？



#### 使用联合索引查询是如何匹配的？



#### 设计索引时一般要考虑哪些因素？

* 一般是先建数据库表，然后开发业务，业务开发完成时由于系统里所有sql语句都写完了，所以开始考虑创建索引。
* 一般一个表设计两三个联合索引来覆盖where条件、order by条件、group by条件中的字段，然后审查每个sql中的where、order by、group by后面跟的字段顺序，是否能匹配联合索引的最左侧字段开始的部分字段，这样保证所有sql语句都能走索引。
* 假设创建了一个联合索引index(a,b,c),3个sql语句分别是 where a=? and b=? ,order by a,b ,group by a,那么这三个sql都可以用上联合索引
* 如果字段区分度不高，比如10万行数据里就只有0和1两个值，对于这样的数据二分查找相对于全表扫描是无法提高效率的，所以这种字段不如直接走全表扫描，索引意义不大
* 如果字符串类型字段长度太长，建立联合索引时可以取前n个字符做前缀索引。where条件查询时会先到索引树里根据name字段的前n个字符去搜索，过滤得到部分数据后，再回到聚簇索引提取出完整的字段值进行对比；而order by和group by无法使用前缀索引
* 建好索引的字段如果查询时对字段使用了函数或计算，则索引失效
* 索引设计好后如果系统内的所有sql都能走索引则基本没什么问题，但是在后续的增删改操作时会需要更新索引树。插入数据时需要更新聚簇索引树，然后联合索引也需要更新，不停的增删改就会不停更新所有索引树。如果主键索引不是自增的而是自定义无序的，插入数据时会导致索引树里的页分裂，页分裂是为了保证索引的大小顺序，有序才能使用二分查找进行搜索，而页分裂是很耗费时间的。所以最好使用自增主键而不要使用uuid，使用自增主键由于本身是有序的，所以插入只是很自然的新增一个页，如果使用uuid会导致聚簇索引频繁进行页分裂

#### 案例实战:设计陌生人社交APP的MySQL索引

系统背景:一般进入陌生人社交app后，一般是根据条件筛选不同的人并查看信息，所以是对user_info表的查询，表中需要包含省份城市，性别，身高，体重，兴趣爱好，性格特点，照片，最后一次上线时间。可能需要where，order by，limit来查询

当where与order by只能有一个走索引，一般选择让where走来过滤信息

省份、城市、性别是搜索时必定包含的三个字段，所以把这三个字段放在联合索引的左侧，

最左侧连续多个字段的原则
核心重点就是尽量利用一两个复杂的多字段联合索引，抗下80%以上的查询，然后再用一两个辅助索引抗下剩余20%的非典型查询，这样99%以上的查询都能充分利用索引，就能保证查询速度和性能

#### SQL语句的执行计划和性能优化有什么关系？

一个sql语句，在mysql底层针对磁盘上的大量数据表，聚簇索引，二级索引，是如何检索查询，如何筛选过滤，如果排序，如何分组，到底怎么把查询结果查出来，这就是mysql的执行计划，表示底层是如何执行sql的，根据执行计划去优化sql，这就是sql调优

#### 执行计划中包含哪些内容？

* 如果当前二级索引是唯一索引(unique key)，通过索引直接快速查找数据的过程，在执行计划里叫const，意思就是性能超高的常量级。
* 如果当前索引是普通索引，查询速度也是很快的，在执行计划里叫做ref

const:使用了主键索引/唯一索引来访问

ref:使用了普通索引，或者是用主键索引/唯一索引字段弄了一个is null/is not null

ref_or_null:使用了普通索引，并且限制了值is null(例如select * from table where name=x or name is null)，也就是说在普通索引中进行等值匹配以及null值，然后再回表去聚簇索引中查询，因为同时有索引等值比较和null值查询，所以叫做ref_or_null

range:sql中利用索引做了范围筛选，例如select * from table where age>=x and age<= x

当age是一个普通索引且用age进行了范围筛选，这种方式就是range

index:只需要遍历二级索引就可以拿到想要查询的数据，而不需要到聚簇索引回表查询的方式，叫做index访问方式，本质是遍历索引而不是全表查询。例如给一个表建了一个联合索引key(x1,x2,x3),查询sql为select x1,x2,x3 from table where x2=xx,由于where中的x2无法使用联合索引来查询，只能直接遍历索引(x1,x2,x3),找到x2=xx的数据后，把x1、x2、x3三个字段值从索引结果中提取出来即可。遍历二级索引比遍历聚簇索引(全表扫描)快多了,因为二级索引叶子节点字段值少，比聚簇索引叶子节点小多了，所以速度快

all:直接全表扫描，扫描聚簇索引的所有叶子节点，也就是一行一行数据去扫描

总结:ref和const，range本质都是基于索引树的二分查找和多层跳转查询，都是很快的，一般问题不大，除非通过索引查出来的数据量太多了。index的话，由于是遍历二级索引树的叶子节点查询，肯定比基于索引树的二分查找慢多了，但是性能还是好于全表扫描

#### 平时写的业务sql是如何使用索引的？

比如"select * from table where x1 = xx or x2>=xx"，建索引时可能是对字段x1和x2分别建了索引，也可能是对(x1,x3),(x2,x4)建立索引。而这个sql在查询时只能选择一个索引去用，负责生成执行计划的是查询优化器，由查询优化器来选择使用哪个索引，一般会选择在索引里扫描行数比较少的那个索引。

查询过程:由于等值比较扫描数据较少，所以选择使用x1索引，也就是ref方式，找到几条数据后，再带着数据(只存有索引值和主键id)进行回表，回到聚簇索引里查出每条数据的完整数据，然后加载到内存中，再根据x2>=xx这个条件进行筛选后得到最后结果。

查询优化器一般只会选择一个索引，但是也有些场景是同时查多个索引树然后对结果取交集的，然后拿交集回表到聚簇索引。

#### 多表关联查询是如何执行的？

多表关联的执行原理:

from后面直接跟两个表名，就是针对两个表进行联表查询了，如果没有其他任何限制，就会得到一个笛卡尔积。比如t1表有10条数据，t2表有5条数据，当select * from t1，t2时，t1表里的每一条数据都会跟t2 表里的数据连接起来再返回，所以是10 * 5=50，会查出50条数据，这就是笛卡尔积。

```mysql
SELECT
	*
FROM
	t1,
	t2
WHERE
	t1.x1 = "A"
AND t1.x2 = t2.x2
AND t2.x3 = "B"
```

以上sql中 t1.x1="A",是针对t1表的数据筛选条件，本质是从t1表里筛选出一些符合条件的数据出来再跟t2表做关联，而不是多表关联条件。t2.x3="B"也不是关联条件，也是针对表t2的筛选条件。真正的关联条件是t1.x2=t2.x2，意思是说在表t1里的每条数据跟表t2做关联时，要求t1表中每条数据的x2值和表t2的x2字段值相等。比如t1表中有1条数据的x2值为"A",t2表里有两条数据的x2字段值为"A",此时就会把t1表里的1条数据跟t2表中的两条数据分别关联起来，最终会返回两条关联后的数据。

多表关联查询时，可能是先从一个表里查出一波数据，这个表叫做"驱动表"，再根据这波数据去另外一个表里再查询一波数据然后进行关联，另一个表叫做"被驱动表"

#### 多表关联的分类

多表关联，主要就是内连接和外连接。

内连接:inner join,只有两个表的数据能完全关联上，才能作为返回结果，并且内连接的连接条件是可以放在where语句里的

外连接:outer join,分为左外连接和右外连接。外连接的连接条件必须放在on子句中，不能放在where子句中

* 左外连接的意思是，在左侧表的里某条数据如果在右侧表中关联不到任何数据，也要把左侧表这条数据返回。
* 右外连接的意思是，在右侧表里的某条数据如果在左侧表中关联不到任何数据，也要把右侧表的数据返回

假设有一个员工表employee，一个产品销售业绩表product_sale，如下:

| 员工表 employee  |           |                 |
| ---------------- | --------- | --------------- |
| employee_id 主键 | name 姓名 | department 部门 |

| 销售业绩表product_sale |                    |                      |                      |
| ---------------------- | ------------------ | -------------------- | -------------------- |
| product_sale_id 主键   | employee_id 员工id | product_name产品名称 | saled_amount销售业绩 |

1.如果想看每个员工对每个产品的销售业绩:

```mysql
SELECT
	em.name,
	em.department,
	ps.product_name,
	ps.sale_amount
FROM
	employee em,
	product_sale ps
WHERE
	em.id = ps.employee_id
```

查询过程: 从员工表全表扫描，然后根据每个员工id去销售业绩表中找employee_id和员工id相等的数据进行关联。一个员工id可能在销售业绩表中找到多条数据，需要让每个员工和在销售业绩表中找到的数据都关联起来，查询结果如下:

| name | department | product_name | sale_amount |
| ---- | ---------- | ------------ | ----------- |
| 张三 | 大客户部   | 产品A        | 30万        |
| 张三 | 大客户部   | 产品B        | 50万        |
| 张三 | 大客户部   | 产品C        | 80万        |
| 李四 | 零售部     | 产品A        | 10万        |
| 李四 | 零售部     | 产品B        | 20万        |

新问题:如果员工表中有一个人是新员工，入职到现在还没有开单，此时需要把这个员工的数据也一起跟着查询出来，只不过在销售业绩里用null值来表示没有任何业绩。这样的需求用内连接是无法实现的，因为内连接必须要两个表能关联上才能查询出结果，所以此时必须用外连接实现，而且是用左外连接:

```mysql
SELECT
	em. NAME,
	em.department,
	ps.product_name,
	ps.sale_amount
FROM
	employee em
LEFT OUTER JOIN product_sale ps 
ON 
	em.id = ps.employee_id
```

返回结果:

| name | department | product_name | sale_amount |
| ---- | ---------- | ------------ | ----------- |
| 张三 | 大客户部   | 产品A        | 30万        |
| 张三 | 大客户部   | 产品B        | 50万        |
| 张三 | 大客户部   | 产品C        | 80万        |
| 李四 | 零售部     | 产品A        | 10万        |
| 李四 | 零售部     | 产品B        | 20万        |
| 王五 | 零售部     | NULL         | NULL        |

#### 多表关联的实现原理？

本质就是先查一个驱动表，然后根据连接条件去被驱动表里循环查询，然后关联起来！

两表关联的执行原理:嵌套循环关联。也就是说，如果有两个表要一起关联查询，会先在一个驱动表里根据它的where条件筛选出一波数据，假设10条，然后对这10条数据走一个for循环，用每条数据都到被驱动表里根据on连接条件和被驱动表的where条件筛选出数据，找出来的数据就进行关联。这样需要循环去被驱动表里查询10次。

三表关联查询的原理:先从表1查出10条数据，然后去表2里查10次，如果每次在表2种都查出来3条数据，然后关联起来，就会得到一个30条数据的结果集。然后再用这批数据去表3里继续查询30次

#### 多表关联查询速度慢的原因？

从多表关联查询的过程来分析：多表关联查询时，首先从驱动表中用where筛选出一部分数据，然后再对查询结果中每条数据都循环一次去被驱动表里查询数据。这个过程中:

* 第一个影响性能点是如果驱动表索引没建好，那么驱动表根据where条件进行筛选时就会走全表扫描，会影响性能。
* 第二个影响性能点是如果被驱动表索引没建好，在对查询结果进行循环查询并关联时就会走全表扫描，会影响性能

总之，多表关联查询速度慢的答案就是驱动表和被驱动表的索引没有建好。如果驱动表和被驱动表索引建好，多表查询的性能就会很高

#### MySQL是如何根据成本选择执行计划的 

#### MySQL是如何基于各种规则去优化执行计划的？

#### 子查询是如何执行的？它的执行计划是如何优化的？

"select * from t1 where x1= (select x1 from t2 where id=xxx)",此sql执行时分为两步，第一步先执行子查询，根据主键定位出一条数据取出x1字段值，然后再执行外层sql

执行计划的优化:

"select * from t1 where x1 in（select x2 from t2 where x3 =xxx）",子查询查出一波数据，然后判断t1表中哪些数据的x1字段值在结果集中。但是执行计划不是按这样查询的，会对查询进行优化，会先执行子查询，然后把查出来的结果都写入一个临时表，也可以叫做物化表，，也就是说对中间结果集进行物化，物化表可能基于memory存储引擎通过内存存放，假如结果集太大，可能会采用普通的b+树聚簇索引的方式存入磁盘中，无论放在哪里，这个物化表都会建索引的。接下来并不是对t1表全表扫描然后遍历每条数据去根据索引快速查找是否在结果集中，而是判断如果t1表有10万条，物化表有500条，则会全表扫描物化表，对每个物化表中数据去到t1表中进行索引查找，也就是用小表驱动大表

#### 半连接-- semi join

"select * from t1 where x1 in(select x2 from t2 where x3=xxx)",mysql对执行计划优化后会吧子查询转成一个半连接:

"select t1.* from t1 semi join t2 on t1.x1=t2.x2 and t2.x3=xxx"。semi join的语义，和in子句+子查询语义是完全一样的，

#### explain命令得到sql执行计划

用explain + sql，就可以拿到这个sql的执行计划，也就是mysql是如何访问这个表的

| id   | select_type | table | partitions | type | possible_key | key  | key_len | ref  | rows | filtered | extra |
| ---- | ----------- | ----- | ---------- | ---- | ------------ | ---- | ------- | ---- | ---- | -------- | ----- |
|      |             |       |            |      |              |      |         |      |      |          |       |

id:一个复杂sql里可能会有很多个select，也可能会包含多条执行计划，每个执行计划都有一个唯一id

select_type：查询类型

type：const，ref，range，index，all，

possible_keys：type确定了访问方式后，可供选择的索引

ref:

rows:大概会读取多少条数据

extra:额外信息，不太重要

#### 使用MySQL为什么要搭建主从复制架构？(也就是说，主从复制架构有什么用处？)

主从复制的两个作用:

* 实现高可用: 单机部署后如果出现单点故障会导致数据库不可用，进而导致整个 Java 业务系统不可用。所以真正的生产架构需要实现高可用，实现高可用主要靠主从复制架构+高可用工具。

* 做读写分离架构: 主节点负责全部数据的写入，从节点负责全部数据的查询。

  读写分离架构是怎么提高性能的？假设一台 8 核 16 GB 的 MySQL单机服务器每秒最多能抗 4000 读写请求。而现在java业务系统负载为每秒2500写请求+2500读请求，显然一台机器扛不住。而使用了主从复制来做读写分离后，使用两台机器一主一从，让2500个写请求落到主库，2500个读请求落到从库，这样就解决了性能问题。并且一般 Java 系统业务场景都是读多写少，mysql的主从复制支持一主多从，当读请求压力继续增加时，可继续横向加机器做从节点。读写分离一般使用mycat或者sharding-sphere之类的中间件来实现。

一般生产环境中 MySQL 高可用架构是必做的。但是读写分离架构并不是必做的，等业务并发量到达一定程度再去做

#### 主从复制还有哪些其他应用场景？

* 可以单独挂载一个从库专门用来执行报表类的查询sql，因为这种报表类的sql一般都上百行，运行要好几秒。所以单独用一个从库，从而不影响主库的运行。

#### MySQL主从复制的原理？

MySQL 在执行增删改时会记录 binlog。当我们在从库上配置好主库信息后，从库的一个io线程会主动跟主库建立一个tcp连接并请求主库将binlog发送过来，这时主库上有一个io dump线程负责通过这个tcp连接把binlog发给从库的io线程，io线程把收到的binlog写入自己本地的relay中继日志文件中，这时从库上的sql线程会读取relay日志并进行日志重做来把所有在主库执行过的增删改操作在从库上做一遍来还原数据。

#### 那如何为MySQL搭建一套主从架构呢？

首先在两台机器上安装好 MySQL，并检查确保主库和从库的server-id是不同的，然后打开主库的binlog功能。并在主库上执行如下配置:

```bash
# 在主库上创建一个用于主从复制的账号
create user `backup_user`@`192.168.3.%` identified by `backup_123`;
grant replication slave on *.* to `backup_user`@`192.168.31.%`;
flush privileges;
```

如果主库已经存在许多数据，则需要先将系统停机保证不再写入数据，然后使用mysqldump工具做一个全量备份:

```bash
# --master-data=2意思就是在备份sql中记录一下此时主库的binlog文件和postion号，为主从复制做准备
/usr/local/mysql/bin/mysqldump --single-transaction -uroot -proot --master-data=2 -A > backup.sql
```

然后把backup.sql拷贝到从库上去执行完。然后打开backup.sql，找到

```bash
master_log_file=`mysql-bin.000015`,master_log_pos=1689
```

然后根据backup.sql中找到的内容在从库mysql命令行中执行命令来指定主库进行复制:

```bash
change master to master_host=`192.168.31.229`,
master_user = `backup_user`,master_password=`backup_123`,
master_log_file=`mysql-bin.000015`,master_log_pos=1689;
```

然后执行start slave命令开始主从复制。最后用show slave status查看一下主从复制状态，如果看到Slave_IO_Running和Slave_SQL_Running都是yes表示本次配置成功，主从复制已经开始了。这是一个异步复制，所以会出现短暂的主从不一致。

异步复制时，主库把日志写入binlog后直接提交事务返回了，并没有去保证从库一定接收到了这条日志，如果此时主库宕机，即使进行主从切换，也会造成数据丢失，因为从库并没有这条记录。所以MySQL用半同步复制机制来解决这种场景带来的问题: 就是说当主库写入数据并记录binlog后，要确保binlog复制到从库了，才能告诉请求客户端本次事务写入成功。这样即使主库宕机，把从库切换为主库，数据也不会丢失。

#### 半同步复制有哪两种实现方式？

第一种: after_commit 方式，非默认方式。当主库写入binlog时，等binlog复制到从库时，主库就提交自己的本地事务，然后等待从库给主库返回成功的响应，主库再返回提交事务成功的响应给客户端

第二种:MySQL 5.7 的默认方式。主库写入 binlog，然后复制给从库，等待从库给主库返回成功，主库再提交事务，然后再返回提交事务成功的响应给客户端

#### 如何搭建半同步复制？

在搭建好异步复制的基础上，先在主库安装半同步复制插件，并开启半同步复制功能:

```bash
# 以下命令在MySQL命令中执行
# 插件名称在linux环境是".so"，如果是windows环境，则改为".dll"
install plugin rpl_semi_sync_master soname `semisync_master.so`;
set global rpl_semi_sync_master_enbale=on;
show plugins;
# 如果能看到安装了这个插件，存在则主库半同步插件安装成功
```

然后在从库安装插件并开启半同步复制功能:

```bash
install plugin rpl_semi_sync_slave soname `semisync_slave.so`;
set global rpl_semi_sync_slave_enable=on;
show plugins;
# 检查插件列表是否存在当前安装的插件，存在则从库半同步插件安装成功
```

然后重启从库的IO线程:

```bash
stop slave io_thread;
start slave io_thead;
```

最后在主库上检查半同步复制是否在正常运行:

```bash
show global status like `%semi%`;
# 如果看到 Rpl_semi_sync_master_status的状态为on则完成
```

#### 如何基于GTID搭建主从复制？

MYSQL主从复制，除了搭建半同步复制模式，还有一种是GTID搭建模式:

在主库上mysql配置文件上配置:

```bash
gtid_mode=on;
enforce_gtid_consistency=on
log_bin=on
# 单独设置一个
server_id=2
binlog_format=row
```

然后在从库mysql配置文件上进行配置:

```bash
gtid_mode=on
enforce_gtid_consistency=on
log_slave_updates=1
# 单独设置一个和主库不同的id
server_id=3
```

然后创建用于主从复制的账号，然后从主库停止写入，dump出备份sql，在从库执行一遍，然后然后把backup.sql拷贝到从库上去执行完。然后打开backup.sql，找到

```bash
@@GLOBAL.GTID_PURGED=XX
```

然后根据backup.sql中找到的内容在从库mysql命令行中执行命令来指定主库进行复制:

```bash
change master to master_host=`192.168.31.229`,
master_user = `backup_user`,master_password=`backup_123`,
@@GLOBAL.GTID_PURGED=XX;
```

然后在从库执行查询:

```bash
# 找到executed_gtid_set,里面记录的事执行过的 gtid
show master status;
# 接着执行下面的命令与上面的结果做对比
select * gtid_executed;
# 对应上说明已经开始gtid复制了
```

#### 如何解决主从复制带来的数据延迟？

主从复制为什么会产生延迟？

很简单，由于主库是多线程并发写入，但是从库是单个线程过来拉取数据的，所以导致了从库复制速度较慢。主从之间延迟时间可以使用percona-tookit工具集中的pt-heartbeat工具，工具会在主库创建一个heartbeat表，然后有一个线程定时更新表中时间戳字段，然后从库上有一个monitor线程负责检查主库同步过来的heartbeat表里的时间戳。

主从复制延迟会导致什么问题？

如果基于主从复制做了读写分离架构，主从复制延迟就会导致系统刚写入一条数据到主库，但是立即在从库中读取会发现读取不到。

如何解决复制延迟？

也就是说让从库也用多线程并行复制数据就可以了，这样从库复制的足够快就能大大降低延迟。具体做法是:mysql5.7开始就支持并行复制了，可以在从库mysql配置文件中配置:

```bash
slave_parallel_workers>0
slave_parallel_type=LOGICAL_CLOCK
```

如果在读写分离架构下还是有刚刚写入的数据需要立即被读到，可以在mycat或者sharding_sphere等中间件中设置读写强制都从主库走，这样刚写入的数据就能立即被读到。

在搭建读写分离架构时，如果对数据丢失不敏感，可以使用异步复制再搭配从库并行复制机制。

如果对mysql要做高可用来保证数据绝对不丢失的话，还是要使用半同步复制，然后搭配从库并行复制机制

#### 如何让MySQL基于主从复制实现故障转移保证高可用？也就是说如何实现故障转移？

一般生产环境里使用MHA工具，也就是Master High Availability and Tools for MySQL,日本人使用perl脚本写的一个工具。MHA需要单独部署，分为Manager节点和Node节点。Manager节点一般是单独部署一台机器，Node节点需要部署在MySQL机器上，因为Node节点需要去解析MySql日志进行一些操作。而manager节点会通过探测集群里的node节点来判断
