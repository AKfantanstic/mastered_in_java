# Java内存模型(Java Memory Model)
线程的工作内存和主内存之间的交互
* read:线程从主内存中读取数据
* load:将线程从主内存中读取的数据载入线程工作内存
* use:线程从工作内存中引用变量
* assign:线程向工作内存中写入变量
* store:工作内存中数据修改
* write:将变量写回主内存

# 指令重排和happens-before:
编译器、指令器可能对代码重排序，目的是为了执行更快，但不是所有的情况都允许它这种重排序优化的，所以happens-before原则指定了8种不可以重排序优化的情况。如果不符合happens-before原则指定的8种情况，那可以随意进行重排序优化

* 1.程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作
* 2.锁定规则：一个unLock操作先行发生于后面对同一个锁的lock操作，比如说在代码里有先对一个lock.lock()，lock.unlock()，lock.lock()
* 3.volatile变量规则：对一个volatile变量的写操作先行发生于后面对这个volatile变量的读操作，volatile变量写，再是读，必须保证是先写，再读
* 4.传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C
* 5.线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作，thread.start()，thread.interrupt()
* 6.线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生
* 7.线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行
* 8.对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始

### Jvm中有哪几块内存区域？Java 8之后对内存分代做了什么改进？哪些区域可能发生 OutOfMemoryError
* tomcat部署时，我们启动的不是自己的系统，tomcat是一个jvm进程，而JVm是一个进程，我们写的系统只不过是一些代码，放在tomcat的目录里，tomcat会去加载我们的代码到jvm里去。tomcat
去负责接收请求，执行我们写好的代码，基于spring框架的一大堆代码

jvm中的内存区

* Java8以后的内存分代改进:1.8之前，永久代里存放着常量池和类信息，1.8及之后，将常量池移到堆中，将类信息移到metaspace(元数据区)，移除了永久代

### 运行时数据区结构？
运行时数据区分为两块:
>1. 线程共享的数据区: 包括方法区和堆  
>2. 线程私有的数据区: 程序计数器，虚拟机栈，本地方法栈

## Java 通过引入字节码这种中间表达方式，屏蔽了不同硬件的差异，由 JVM 负责完成从字节码到机器码的转化。

### 生产环境的tomcat是如何设置jvm参数的？如何检查jvm运行情况？
* 第一种是通过tomcat部署的，那么你的系统仅仅是在tomcat的jvm进程中执行，需要查看tomcat的配置脚本，catalina脚本里面找，里面有对应的tomcat启动时的一些jvm参数
* 第二种是通过java命令直接启动你系统中的main方法，java命令后面可以带上一些jvm参数

### 实际项目中是否做过jvm gc优化？
通过预估+压测，做一份生产环境的jvm参数出来，并通过观察对jvm的监控参数来对出现的问题，通过修改参数来优化jvm的运行，比如出现full gc问题如何进行优化。

一定要结合你自己的业务，系统，接口，干什么，并发请求，jvm运行的情况，问题出在哪儿，如何调优，效果如何

### 产生oom的原因？
* 第一:内存泄漏问题导致的
* 第二:少数互联网公司由于超高并发导致oom瞬时大量存活对象占据内存，导致没法创建更多的对象了。
* 你也得去思考，甚至去模拟一下，最好可以模拟出来，oom不是你自己的代码，可能是你依赖的第三方的组件，netty导致的，结合自己的项目去一步一步的分析，oom问题的产生，和解决的过程
### 1. 代码解释什么是循环引用:
```
class  A {
    public B bb;
}

class  B {
    public A aa;
}

public class TestGC {

    public static  void main(String[] args) {
	A a = new A();
	B b = new B();

	a.bb = b;
	b.aa = a;

	a = null;
	b = null;
    }
}
```
在上面的代码示例中，假设我们有两个类分别是A和B，A类中有一个字段是B类的类型，B类中有一个字段是A类类型，现在分别new一个A类对象和new一个B类对象，
此时引用a指向刚new出来的A类对象，引用b指向刚new出来的B类对象,然后将两个类中的字段互相引用一下，这样即使下面进行a = null和b = null，
但是A类对象仍然被B类对象中的字段引用着，尽管现在A类和B类独享都已经访问不到了，但是引用计数却都不为0.

### 如何判断一个对象是否存活？（或者 GC 对象的判定方法）
判断一个对象是否存活有两种方法：
1. 引用计数法
所谓引用计数法就是给每一个对象设置一个引用计数器，每当有一个地方引用这个对象时，就将计数器加一，引用失效时，计数器就减一。当一个对象的引用计数器为零时，说明此对象没有被引用，也就是“死对象”,将会被垃圾回收.
引用计数法有一个缺陷就是无法解决循环引用问题，也就是说当对象 A 引用对象 B，对象 B 又引用者对象 A，那么此时 A、B 对象的引用计数器都不为零，也就造成无法完成垃圾回收，所以主流的虚拟机都没有采用这种算法。
2. 可达性算法（引用链法）
该算法的思想是：从一个被称为 GC Roots 的对象开始向下搜索，如果一个对象到 GC Roots 没有任何引用链相连时，则说明此对象不可用。
在 Java 中可以作为 GC Roots 的对象有以下几种：
* 虚拟机栈中引用的对象
* 方法区类静态属性引用的对象
* 方法区常量池引用的对象
* 本地方法栈JNI引用的对象
类的实例变量不是GC Roots

虽然这些算法可以判定一个对象是否能被回收，但是当满足上述条件时，一个对象比不一定会被回收。当一个对象不可达 GC Root 时，这个对象并不会立马被回收，而是出于一个死缓的阶段，若要被真正的回收需要经历两次标记.
如果对象在可达性分析中没有与 GC Root 的引用链，那么此时就会被第一次标记并且进行一次筛选，筛选的条件是是否有必要执行 finalize() 方法。当对象没有覆盖 finalize() 方法或者已被虚拟机调用过，那么就认为是没必要的。 如果该对象有必要执行 finalize() 方法，那么这个对象将会放在一个称为 F-Queue 的对队列中，虚拟机会触发一个 Finalize() 线程去执行，此线程是低优先级的，并且虚拟机不会承诺一直等待它运行完，这是因为如果 finalize() 执行缓慢或者发生了死锁，那么就会造成 F-Queue 队列一直等待，造成了内存回收系统的崩溃。GC 对处于 F-Queue 中的对象进行第二次被标记，这时，该对象将被移除” 即将回收” 集合，等待回收。

### 6.JVM 优化 Java 代码时都做了什么？
jvm对代码执行的优化分为两部分:运行时优化 和 即时编译器优化(JIT)
      
运行时优化：比如说锁机制（如偏斜锁）、内存分配机制（如 TLAB）等     
即时编译器优化： 是指将热点代码以方法为单位转换成机器码，直接运行在底层硬件之上

### 7. JVM的运行参数怎么指定？
* 如果用IDEA等开发工具，来启动运行项目，那么要调试JDK就方便多了，只需要将参数值设置到VM options中即可。  
* 如果在Linux上运行jar包，则需要用下面命令运行:
```
java -jar -XX:MetaspaceSize=128m
-XX:MaxMetaspaceSize=128m
-Xms1024m -Xmx1024m -Xmn256m -Xss256k
-XX:SurvivorRatio=8
-XX:+UseConcMarkSweepGC xxx.jar
```

### 9.新生代的垃圾收集过程是怎样的？
* 新生代主要采用复制算法,过程：当Minor GC 开始时，将Eden区和from-survivor区存活的对象年龄加1，然后分别复制到to-survivor区，然后将eden区和from-survivor区清空，
最后将from-survivor和to-survivor交换，此时的状态是eden区为空，from-survivor区有对象，to-survivor区为空。
每次Minor GC 后各区都保持这个状态。

* 关于Eden、两个Survivor的细节。
1、大部分对象创建都是在Eden的，除了个别大对象外。
2、Minor GC开始前，to-survivor是空的，from-survivor是有对象的。
3、Minor GC后，Eden的存活对象都copy到to-survivor中，from-survivor的存活对象也复制to-survivor中。其中所有对象的年龄+1
4、from-survivor清空，成为新的to-survivor，带有对象的to-survivor变成新的from-survivor。重复回到步骤2

### 10.新生代的对象的内存分配过程是怎样的？
我们知道普通的对象会被分配在 TLAB(Thread Local Allocation Buffer) 上；如果对象较大，JVM 会试图直接分配在 Eden 其他位置上；如果对象太大，
完全无法在新生代找到足够长的连续空闲空间，JVM 就会直接分配到老年代。大对象具体是多大，取决于使用的gc是哪种，
cms是PretenureSizeThreshold，G1是region大小的一半

### 12.热点代码的调用次数在 JVM 不同模式下分别是多少？
* 运行时，JVM 会通过类加载器（Class-Loader）加载字节码，解释或者编译执行。主流 Java 版本中，如 JDK 8
实际是解释和编译混合的一种模式，即所谓的混合模式（-Xmixed）。通常运行在 server 模式的 JVM，会进行上万次调用
以收集足够的信息进行高效的编译，client 模式这个门限是 1500 次。Oracle Hotspot JVM 内置了两个不同的 JIT 
compiler，C1 对应前面说的 client 模式，适用于对于启动速度敏感的应用，比如普通 Java 桌面应用；C2 对应 
server 模式，它的优化是为长时间运行的服务器端应用设计的。默认是采用所谓的分层编译（TieredCompilation）。

### 13. Java 是解释执行”，这句话正确吗？
* 这个说法不太准确。大部分代码是通过 JVM 内部的解释器来将字节码转换成机器码来解释执行的。但是不同厂商提供的 JVM 都提供了
JIT编译器(Just In Time,即时编译器),JIT 能在运行时将热点代码直接编译成机器码，这种情况就属于编译执行了。
* ***扩展1***：写个程序直接执行字节码就是解释执行。写个程序运行时把字节码动态翻译成机器码就是jit。写个程序把java源代码直接翻译为机器码就是aot。造个CPU直接执行字节码，字节码就是机器码。
* ***扩展2***：解释执行和编译执行的区别，可以类比一下，解释执行是同声传译，编译执行是放录音

### 14. JVM运行参数及说明:
* 指定“-Xint”，就是告诉 JVM 只进行解释执行，不对代码进行编译，这种模式抛弃了 JIT 可能带来的性能优势。毕竟解释器（interpreter）是逐条读入，逐条解释运行的。
* “-Xcomp”参数，这是告诉 JVM 关闭解释器，不要进行解释执行，或者叫作最大优化级别.-Xcomp”会导致 JVM 启动变慢非常多，同时有些 JIT 编译器优化方式，比如分支预测，
如果不进行 profiling，往往并不能进行有效优化。

### 15. JIT为什么能提高运行速度？
* JIT 这种基于运行时统计分析热点代码，并对热点代码进行编辑成机器码的这种设计，是因为绝大多数的程序都表现为“小部分的热点代码的运行耗费了大多数的资源”

### 16. Hotspot虚拟机是如何判定为热点代码的？
* Hotspot 热点探测使用的方法是调用计数器和回边计数器，虚拟机为每个代码块，每个方法，建立计数器，统计执行次数，超过一定阀值，
就视为热点代码，这种实现较为复杂，但是结果更为严谨

### 17.JVM中哪些区域可能发生OutOfMemoryError？ 

### 18.什么是准确式内存管理？
HotSpot就是基于准确式内存管理。准确式内存管理是指虚拟机可以知道内存中某个位置的数据具体是什么类型。
譬如内存中有一个32bit的整数123456，虚拟机将有能力分辨出它到底是一个指向了123456的内存地址的引用类型还是一个数值为123456的整数，
准确分辨出哪些内存是引用类型，这也是在垃圾收集时准确判断堆上的数据是否还可能被使用的前提。
由于使用了准确式内存管理，Exact VM可以抛弃掉以前Classic VM基于句柄（Handle）的对象查找方式
（原因是垃圾收集后对象将可能会被移动位置，如果地址为123456的对象移动到654321，
在没有明确信息表明内存中哪些数 据是引用类型的前提下，那虚拟机肯定是不敢把内存中所有为123456的值改成654321的，
所以要使用 句柄来保持引用值的稳定），这样每次定位对象都少了一次间接查找的开销，显著提升执行性能
HotSpot虚拟机的热点代码探测能力可以通过执行计数器 找出最具有编译价值的代码，
然后通知即时编译器以方法为单位进行编译。如果一个方法被频繁调 用，或方法中有效循环次数很多，
将会分别触发标准即时编译和栈上替换编译（On-Stack Replacement，OSR）行为。

### 32位Java虚拟机中的long和double变量写操作为何不是原子的？
* 32位虚拟机对long和double这种64位的基础类型，是分为两个32位来存储的，所以32位虚拟机中对long/double类型变量的简单赋值操作，不保证原子性，也就是说不是原子的。如果多个线程同时并发修改long i = 30,
因为long是64位的，就会导致有的线程在修改i的高32位，有的线程在修改i的低32位，所以在32位虚拟机下给i赋值，可能导致i的值不是30，可能是类似-3333554566这种乱码一样的数字。

### JVM 对 synchronized锁的优化:锁消除、锁粗化、偏向锁、自旋锁
从 JDK 1.6 ，JVM 对 synchronized 锁进行了许多优化。优化点就是底层加锁实现方式是不同的，可能以偏向锁的方式加锁，以自旋锁的方式加锁，以轻量级锁的方式加锁，而且锁可以升级。这些东西只要了解概念就可以了，jdk1
.6开始对 synchronized 关键字做过哪些优化，有哪些加锁方式，效果是什么，作用是什么，但是实际开发和使用中，根本不需要过多去care一些东西。
* 锁消除: 锁消除是jit即时编译器对synchronized锁做的优化。在编译时候通过逃逸分析技术，来分析 synchronized 
锁对象，是不是只能被一个线程来加锁，而没有其他线程来竞争加锁，如果是这种情况，那么编译时就不用加入monitorEnter和monitorExit指令。优化思想是，如果仅仅一个线程争用锁而不涉及到多个线程竞争锁时，就可以消除这个锁了，提升这段代码的执行效率
* 锁粗化:如果 jit 即时编译器发现代码里有多个代码块连续多次加锁释放锁的，会把这多个代码块合并为为一个锁，这就是锁粗化，用一个锁来粗化加锁粒度，避免频繁多次加锁释放锁
* 偏向锁: monitorEnter 和 monitorExit 是用 CAS 操作来加锁和释放锁的，开销较大，因此当发现大概率只有一个线程来获取锁，就会给这个锁对象维护一个偏好(Bias),
后面这个线程再来加锁和释放锁，就基于 Bias 来执行而不需要通过 CAS ，提升性能。但是如果有偏好之外的线程来竞争锁，就会收回之前分配的偏好。升级为轻量级锁
* 轻量级锁: 如果偏向锁因为不同线程竞争锁太频繁加锁失败，就会尝试采用轻量级锁的方式来加锁，就是将对象头的 markWord 里有一个轻量级锁指针，尝试指向持有锁的线程，然后判断一个是不是自己加的锁，如果是自己加的锁就执行代码，如果不是自己加的锁就加锁失败，说明有其他人加了锁，这时升级为重量级锁
* 适应性自旋锁:这是 jit 编译器对锁做的另一个优化，如果各个线程持有锁的时间都很短，这时如果一个线程没竞争到锁，就会暂停发生上下文切换，让其他线程来执行。但是得到锁的线程很快释放锁了，然后暂停的线程再次被唤醒，在这种情况下，线程会频繁上下文切换导致开销过大。优化思想:针对这种每个线程持有锁时间很短的情况，可以采用忙等待策略，也就是一个线程没竞争到锁，就进入一个while循环不停等待，不会发生上下文切换，只要在等待的过程中有机会获取到锁然后继续执行就可以了，避免了上下文切换。
* 重量级锁:如果一个线程持有锁的时间很长，那么其他线程获取不到锁就会暂停并发生上下文切换，这种暂停获取锁的方式，就是所谓的重量级锁，这个根据不同情况自动调整的过程，就是自适应的意思。
