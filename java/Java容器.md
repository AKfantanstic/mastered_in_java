## HashMap
对于HashMap这个容器，首先它的数据结构是 1.7及之前是数组加链表 1.8更改为数组 + 链表 + 红黑树。
然后就是存放一个数据的时候是怎样存放的，如何找数组下标，如果发生了扩容后，如何扩容,主要是哈希算法，
以及存放过程可能发生的一系列问题
分为几部分：构造一个hashmap需要的参数及各什么意思及为什么要这么设置，存放数据的过程，移除数据的过程

Hashmap中对hash算法和寻址是如何优化的？
如果底层用entry数组(entry是一个key-value数据结构)实现的话，存元素时候必须先知道该存在数组的哪个下标中，所以用hash值对length-1取模，用这种方式去定位数组下标。

hashmap内部的优化：
在将key-value存入hashmap时，
如果key为null，就放在数组下标为0的位置，这是固定的。
key不为null则先对key计算hash值，这个hash值用int类型来表示，一个int是32位的，源码内部是使用key的hashcode和此hashcode右移16位后的结果进行异或位运算 得到hash值，取模运算比异或位运算开销大，
hash对n取模的结果，和hash和n-1进行或运算效果一样
数学问题:因为a%b == a&(b-1),当b是2的指数时，等式成立。 所以保持数组的长度会一直是2的n次方，只要保持数组长度是2的n次方，hash对n取模的效果，就和hash&(n-1)效果是一样的，而且&运算性能更高

为什么要进行异或运算呢。因为异或是一样两位相异或，结果为0，不一样的结果为1.这样可以进行

hash算法的优化必须和寻址算法结合起来理解，配合起来才能做到提高性能

hash算法的优化：对每个hash值，在它的低16位中，让高低16位进行异或，目的是为了让他的低16位同时保持高低16位的特征，尽量避免一些hash值后续出现冲突，hash冲突会导致大家同时进入数组的同一个位置

寻址算法的优化:用与运算代替取模，提升性能

数组里面存的可能是单个元素，也可能是由多个元素串起来的链表，而数组里存的是链表头元素

链表与红黑树的转化，实际是一个数学问题
O(N)和O(logN)之间的一个大小比较问题

扩容时，需要rehash。扩容时，重新算hash时，原本冲突的key可能在扩容后就不冲突了。在两个key重新对扩容后length取模运算后的结果，判断二进制结果中是否多出一个bit的1，如果没多，那么就是原来的index，如果多了出来，那么就是index+oldcap，通过这种方式来避免rehash的时候，再次用每个hash对新数组length取模，取模性能不高，位运算性能比较高

### 构造函数的参数说明

首先HashMap在jdk1.7和jdk1.8里面的实现是不同的，在jdk1.7中HashMap的底层实现是通过数组+链表的形式实现的，在jdk1.8中HashMap的底层是通过数组+链表+红黑树来实现的。
### Question1: 数组链表是怎么切换的（1.7）？
答：在put的时候采用hash(key)&(len-1)来计算数据存放的index，以此存放元素。当出现哈希冲突的时候，因为有限的数组长度，遭遇哈希冲突，此时就可以使用链表来存储哈希值相同但是值不同的对象。

### Question2：Entry节点如何插入链表（1.7）？
答: Entry节点插入链表是使用头插法来实现的，主要的实现是通过其CreateEntry来实现的，Entry的构造方法中可以协助头插的顺利进行，使用头插法是考虑到热点数据的问题，当时的想法是最近插入的元素，最近也可能被使用，头插入的实现可以缩短链表查找元素的时间。

### Question3：jdk1.8以后为什么改用尾插入?
答：根据initialCapacity*LoadFactoor=capacity以后，如果插入的元素容量达到了capacity，此时会进行扩容，扩容操作按照源码中的写法，主要有两步：1.扩容一个新的Entry，容量为原来的两倍。2.进行Rehash操作，将原来的数据复制到新的Entry中。（1.7）如果是头插入的话，当多线程处理的时候，此时如果存在a->b->c链表，当我们rehash以后，有可能变为b->a，然而其他的线程处理完之后，结果可能会造成b->a->b，造成loop成环。一旦寻找数据会造成死循环。
而1.8以后改成尾插入以后，源码中使用了一个高位来识别之前的数据和插入的新数据，保持了之前的顺序，解决了1.7中可能造成成环的问题。具体的实现是扩容只有最高位会多出一个1，如果之前的数据一旦e & oldCapacity = 0，表明是原来的数据，保持就好，如果是为1，表明是即将插入的新数据，此时保持插入高位，这样就避免了成环的问题。

### Question4：为什么要进行Rehash操作？
答: 因为此时的长度遍历按照index=hashcode & (len - 1)的计算，此时的规则变了，所以需要进行rehash操作。

### Question5：HashMap为什么不是线程安全？
答：在jdk1.7中即使不出现死循环，由于put操作未加锁，我们也不能确保对于多个线程同时执行put操作时，上一秒修改完的put的值，下一秒get是否是修改后的值，容易被其他线程的值所覆盖，线程安全无法保证（1.7&1.8都是如此）

### Question6：为啥源码的容量初始化大小为16?
答：在源码中有个方法叫做tableSizeFor()，这个方法是为了将当前的容量扩容到一个距离当前容量的2的整次方幂。阿里巴巴手册上也建议使用HashMap需要设置一个初始化的容量值，一般来说是设置为16，为什么是16而不是8或者4，因为4或者8容易导致hashMap扩容，影响性能。只要输入的HashCode分布是相对均匀的，那么hash算法就是均匀的，所以给16主要也是为了实现均匀分布。

### Question7：为啥重写equals方法的同时需要重写hashCode方法？使用HashMap举例子说明？
答: 首先，equals方法继承了Object的equals方法，比较的对于值对象比较的是两个对象的值是否相等，对于引用对象比较的是两个对象的内存地址是否相等。上面也说到HashMap是通过hash(key)&(len-1)去寻找index的，index相同就形成链表存储数据，但是假如一个index中存储了object1、object2对象，他们的hash值相同，此时如果我们get数据object2，get(key)此时将会有两个值，你怎么能确保获取到的是object2而不是object1，此时就需要使用equals来比较对象的key是否相同，这样才可以获取到对的对象。实质上在底层get方法的实现是通过getNode(hash(key),key)来实现的，前面的是hash值，后面的是equals对比的对象。

### Question8：HashMap线程不安全不适合多线程，那用什么可以替代？
答：可以使用HashTable或者ConcurrentHashMap来替代HashMap，但是HashTable仅仅是使用synchronized来实现同步锁，从而使得线程安全，但是并发度不高。所以一般使用ConcurrentHashMap来替代

### Question9：为什么在1.8中当链表长度为8时转换为红黑树，数据长度为6时转化为链表？
答: 首先从时间复杂度方面来分析的话，当长度为6时查找的平均长度为6/2=3，（底层会判断偏后还是偏前，以此来从后或者从前遍历），而红黑数log6=2.6，如果为8的时候，此时8/2=4，而log8为3，至于具体这样选，是一种空间和时间的权衡。

# ConcurrentHashMap: ConcurrentHashMap是线程安全的
JDK1.8之前，多个数组，分段加锁，一个数组用一个锁锁住
JDK1.8，优化了之前的细粒度加锁，改为底层用一个数组实现，每个元素进行CAS，如果失败说明有人了
如果两个线程都在数组[5]的位置进行put，采取的是cas的策略，同一个时间点，只能有一个线程能成功执行这个cas。可能有多个线程在同时cas循环，但是一个确定的时间点，只会成功一个cas，由硬件指令保证。此时synchronized对数组元素加锁，链表+红黑树处理，对数组每个元素加锁。
如果你是对数组里同一个位置的元素进行操作，才会加锁串行化处理；如果是对数组不同位置的元素操作，此时大家可以并发执行的
