## "update user set name = 'XXX' where id = 10" 的更新过程？
先把要更新的这行记录从磁盘文件加载到缓冲池，然后对这行记录加锁后将这行数据的旧值记录到undo日志中。然后先更新内存缓冲池中的记录，然后将更新写入到redo log buffer中，redo log buffer是一块内存缓冲器，redo log buffer 有3种策略将数据写入磁盘中，
通过innodb_flush_log_at_trx_commit来配置。写完redo 
log后会将binlog按刷盘策略来写入磁盘写完binlog后，进入事务的最终提交阶段，会把本次更新对应的binlog文件名和本次更新内容记在binlog文件中的位置，都写入到redo log中，同时在redo 
log文件中写入一个commit标记，整个事务完成。commit标记用于保持redo log和binlog的一致性，假如刚刚将redolog写入磁盘文件，mysql宕机了，此时机器恢复后，由于redo log中没有commit标记，所以mysql判定此次事务不成功。假如将binlog写入磁盘了，然后mysql宕机了，此时同样会因为redo log中没有commit标记，认定此次事务不成功，必须是在redo log中写入commit标记后，才算此时事务提交成功，这时redolog 中有本次更新对应的日志，binlog中也有本次更新对应的日志，这时redo log和binlog是完全一致的。最后由后台IO线程将脏页刷回磁盘。

* 当参数为0时，提交事务时不会将redo log buffer里的数据写入磁盘，这种情况下当mysql宕机事务数据会丢失。
* 当参数为1时，提交事务时必须将redo log buffer中数据写入磁盘，也就是说只要事务提交成功，redo log一定会写入磁盘。此时mysql宕机事务数据也不会丢失，因为即使磁盘数据没有改变，但是redolog磁盘文件已经记录了，当mysql重启后会根据redo log去恢复内容。
* 当参数为2时，提交事务时将redo log写入磁盘文件对应的 os cache里，而不是直接写入磁盘文件，有可能1秒后才会把os cache里的数据写入磁盘。这种情况下，当提交事务后，redolog仅仅停留在os 
cache里没有实际写入磁盘文件，此时如果机器宕机，还是会丢失数据
* 对于redo log的刷盘策略，通常设置为1。也就是提交事务时，redo log必须刷入磁盘文件里，对于数据库这样的严格系统，这样可以保证事务提交后，数据绝不会丢失

## binlog的刷盘策略？
用sync_binlog参数来控制binlog的刷盘策略。
* 默认值是0。意思是把binlog写入磁盘时，不直接写入磁盘文件而是写入os cache内存中，此时宕机，os cache中binlog会丢失
* 参数为1。会强制在事务提交时，将binlog写入磁盘文件里。这样即使提交事务后机器宕机，binlog也不会丢。

生产经验:
Java应用系统部署在4核8G机器上，每秒可以抗500左右并发量。
一般8核16G的机器部署MySQL数据库，每秒种可以抗1、2K并发
对于16核32G的机器部署MySQL数据库，每秒可以抗2、3k并发
# 数据库压测需要关注的相关性能指标:
IO相关:
(1)IOPS:指的是机器随机IO并发处理能力，比如200IOPS意思就是说每秒可以执行200个随机IO读写请求。
当在内存bufferPool写入脏数据后，需要后台IO线程在机器空闲时刷回到磁盘，这是一个随机IO的过程。如果IOPS过低，会导致内存里脏数据刷回磁盘的效率太低
(2)吞吐量:指的是机器磁盘每秒可以读写多少字节
当执行sql提交事务时需要将大量redo log等日志写入磁盘，写入redolog一般是一行一行顺序写入，不会进行随机读写，一般SSD顺序写吞吐量可达到每秒200MB
，对于承载高并发来说，SSD磁盘吞吐量不是瓶颈
(3)latency:指的是向磁盘写入一条数据的延迟。当执行sql和提交事务时，需要将redo log顺序写到磁盘，如果写入延迟过高会影响数据库的sql执行性能。写入延迟越低，执行sql的事务的速度就越快，数据库性能就越高
(4)CPU负载:压测中如果CPU负载特别高，就说明已经到达瓶颈，不能继续压测了
(5)网络负载:关注每秒钟网卡会输入多少MB数据，会输出多少MB数据，当到达网络带宽最大值时说明已经出现瓶颈了，就不能再继续压测了
(6)内存负载:如果内存占用过高，也说明不能继续压测了

## 数据库压测工具 sysbench 使用方法:
```
使用如下命令设置yum repo仓库，然后使用yum来安装sysbench
curl -s https://packagecloud.io/install/repositories/akopytov/sysbench/script.rpm.sh|sudo bash
sudo yum -y install sysbench
sysbench --version  
看到sysbench版本号说明安装成功

然后在数据库建好测试库名字叫test_db,然后创建测试账号，然后基于sysbench构建20个测试表，每个表100万条数据，使用10个并发线程对数据库发起访问，连续访问300秒，也就是压测5分钟。
先基于sysbench构造测试表和测试数据:
sysbench --db-driver=mysql --time=300 --threads=10 --report-interval=1 --mysql-host=192.168.11.113 --mysql-port=3306 --mysql-user=root --mysql-password=123456 --mysql-db=test_db --tables=20 --table_size=1000000 oltp_read_write --db-ps-mode=disable prepare

(1)--db-driver=mysql: 基于mysql驱动去连接mysql数据库，如果是oracle、sqlServer可以更换
(2)--time: 连续压测时间，单位秒
(3)--threads=10: 10个线程并发访问
(4)--report-interval=1: 每隔1秒输出压测情况
(5)--mysql-host=127.0.0.1 --mysql-port=3306 --mysql-user=test_user --mysql-password=test_user:指定mysql连接相关信息
(6)--mysql-db=test_db --tables=20 --table_size=1000000: 指定压测数据库，构造20个测试表，每个表100万条测试数据
(7)oltp_read_write: 执行oltp数据库的读写测试
(8)--db-ps-mode=disable: 禁用ps模式
(9)prepare: 按照上面的命令去构造测试数据
   run:运行压测
   cleanup:清理测试数据
   
测试数据库综合读写TPS，使用oltp_read_write模式:
sysbench --db-driver=mysql --time=300 --threads=20 --report-interval=1 --mysql-host=192.168.11.113 --mysql-port=3306 --mysql-user=root --mysql-password=123456 --mysql-db=test_db --tables=20 --table_size=1000000 oltp_read_write --db-ps-mode=disable run

测试数据库的只读性能，使用oltp_read_only模式(将oltp_read_write改为oltp_read_only)

测试数据库的删除性能，使用oltp_delete模式

测试数据库的更新索引字段性能，使用oltp_update_index模式

测试数据库的更新非索引字段的性能，使用oltp_update_non_index模式

测试数据库的写入性能，使用oltp_write_only模式

[ 116s ] thds: 20 tps: 340.03 qps: 6809.60 (r/w/o: 4760.42/1369.12/680.06) lat (ms,95%): 125.52 err/s: 0.00 reconn/s: 0.00
每秒压测报告解读:
(1)thds:20,压测线程数
(2)tps:340.03，每秒执行340.03个事务
(3)qps:6809.60，每秒执行6809.60个请求
(4)r/w/o:760.42/1369.12/680.06 : 每秒6809.60个请求中，有760.42个读请求，1369.12个写请求，680.06个其他请求。也就是对QPS的拆解
(5)lat(ms,95%):125.52 :95%请求的延迟在125.52毫秒以下
(6)err/s:0.00 reconn/s:0.00 :每秒有0个请求失败，发生了0次网络重连

总压测报告:
SQL statistics:
    queries performed:
        read(压测期间执行的总读请求数): 1275694
        write(总写请求数):            364484
        other(总其他请求数):          182242
        total(总请求数):              1822420
    transactions:                        91121  (303.60 per sec.)
    queries:                             1822420 (6072.00 per sec.)
    ignored errors:                      0      (0.00 per sec.)
    reconnects:                          0      (0.00 per sec.)

General statistics:
    total time:                          300.1328s
    total number of events(总执行事务数):  91121

Latency (ms):
         min(请求最小延迟):  12.34
         avg(请求平均延迟):  65.85
         max(请求最大延迟):  1494.97
         95th percentile(95%请求延迟时间): 123.28
         sum:  6000298.15

Threads fairness:
    events (avg/stddev):           4556.0500/20.80
    execution time (avg/stddev):   300.0149/0.03
```

# Buffer Pool:
是数据库中一块基于内存的组件，核心是通过使用内存而不是直接使用硬盘来提高访问速度。Java系统对数据库执行增删改查请求主要就是对这个内存组件中的缓存数据执行的

### 如何配置buffer pool大小？
默认大小下为128MB，有点偏小，对于16核32G机器，可以给BufferPool分配个2GB内存。通过修改配置参数:innodb_buffer_pool_size=2147483648

bufferPool内部结构:buffer_pool中包含多个缓存页，同时每个缓存页还有一个描述数据。当数据库启动时，会按照bufferPool的大小再稍微加大一点去向操作系统申请一块内存区域，作为bufferPool内存区域。然后按照默认缓存页的16KB大小以及800个字节左右的描述数据大小，将整个bufferPool划分成一个一个的缓存页和一个一个的缓存页对应的描述数据。每个描述数据块都是free链表的一个节点，free链表是一个双向链表

## 如何查询一个数据页是否在bufferPool中呢？
数据库中有一张hash表，使用表空间+数据页号作为key，缓存页的地址作为value。当要使用一个数据页时，通过“表空间号+数据页号”作为key去hash表中查询，如果value为空说明缓存页不存在，则需要从磁盘中读取数据页到缓存页中

## 如果bufferPool中的缓存页不够了怎么办？
bufferPool中维护了一个由缓存页的描述数据块作为结点的LRU链表，最近被访问过的数据块一定在LRU链表的头部。当缓存页满了时，就会找出最近最少被访问的缓存页，将这个缓存页刷入磁盘

MySQL使用磁盘存储数据是以页为单位的，BufferPool以页为单位从磁盘中加载数据，叫做缓存页，每个bufferPool中的页会和磁盘上的页一一对应起来，而每一页可能会记录好几行数据，默认情况下一页数据大小是16KB。每页的描述数据大概占页大小的5%用于存储缓存页信息
<bufferPool从磁盘加载页的图>

### 数据库启动时是如何初始化BufferPool的？
数据库启动时，按照配置中的bufferPool大小去找操作系统申请一块内存作为bufferPool缓存区域，申请完毕后按照设定的缓存页大小(默认16KB)以及800字节左右的描述数据大小，把bufferPool划分成一个一个的缓存页和对应的描述数据。划分完成后，缓存页都是空的，只有java系统发起增删改查请求时才会把数据以页为单位从磁盘中读取出来放入bufferPool的缓存页中。
《画图》

### 怎么能知道bufferPool中哪些缓存页是空闲的？
bufferPool中用一个双向链表来管理所有空闲的数据页，叫做free链表，链表中的每个节点都是一个空闲缓存页的描述数据(只要有一个缓存页是空闲的，它的描述数据就会被放到free链表中，数据库刚启动时所有的缓存页都是空闲的，此时所有缓存页的描述数据都在free链表中)，free链表中还有一个基础节点，里面存了free链表的头节点地址和尾节点地址还有free链表中当前还有多少个节点，但这个节点不属于bufferPool
《画图》

### 如何将磁盘上的页读取到bufferPool的缓存页中去？
先从free链表中取一个描述数据块，根据描述数据节点取到对应的空闲缓存页，然后把磁盘上的数据页读取到这个空闲缓存页里，然后把如数据页所属表空间等页相关描述数据写入描述数据块，然后从free链表中去除这个描述数据块就可以了

### 怎么知道数据页有没有被缓存呢？
当java系统向数据库发起增删改查请求时，一定是先判断数据页有没有被缓存，如果没有缓存就走上面的流程从磁盘中加载到bufferPool，如果数据页已被缓存则直接使用。
在数据库内部是使用一个哈希表，以表空间+数据页号为key，缓存数据页内存地址为value，来记录数据页是否被缓存。
当java系统要使用一个数据页时，先以"表空间号+数据页号"作为key去哈希表中查询页是否存在，如果不存在则从磁盘加载，然后在哈希表中写入一个key-value对，key就是表空间号+数据页号，value就是缓存页的内存地址，如果存在则说明数据页已缓存可以直接访问

### 什么原因会造成 bufferPool 中产生内存碎片？
由于bufferPool大小可以自定义，所以划分完缓存页和对应的描述数据后，还剩一点内存，这一点内存无法容纳一个缓存页，只能放着不能用，这点内存就是内存碎片。

### 数据库是如何减少bufferPool的内存碎片的？
如果数据库在给bufferPool划分缓存页时，是东一块西一块的，就会导致缓存页之间产生内存空洞，形成大量内存碎片。
实际上数据库在给bufferPool划分缓存页时是连续分配，会让所有的缓存页和描述数据块都紧密的挨在一起，这样就尽量减少了内存碎片

### 什么是脏页？
Java系统发送给数据库的增删改查请求，最终会在bufferPool中被执行，而磁盘上数据并没有变，这时bufferPool中被修改的缓存页就叫脏页

### 怎么知道哪些缓存页是脏页呢？
BufferPool中使用一个叫做flush链表的双向链表来记录bufferPool中的脏页，凡是被修改过的缓存页，都会把它的描述数据块加入到flush链表中，flush链表结构跟free链表结构几乎一样。flush就是刷脏页的意思，后续是要把脏页flush到磁盘上的

### 如果bufferPool满了，要在bufferPool中淘汰一些缓存页，该淘汰谁？
bufferPool内部使用了一个LRU链表(least recently used,最近最少使用)来记录哪些缓存页是最近最少被使用的。所有从磁盘加载的缓存页的描述数据块都会被这个LRU链表记录，当某个缓存页被访问(查询或修改),就会把这个缓存页的描述数据块挪到LRU链表的头部，也就是说最近被访问的缓存页一定在LRU链表的头部，而尾部保存的就是最近最少被访问的数据页。当bufferPool满了时，就会从LRU链表的尾部开始找到一个缓存页，把缓存页的数据flush到磁盘，然后将数据从缓存页中清空，最后把正在请求的数据从磁盘加载到这个缓存页从中。

### 缓存命中率
在100次请求中，有30次是在查询和修改缓存页中的数据，那么缓存命中率为30%

### 在 SQL 语句中用到的是表和行的概念，而数据库内部是使用表空间和数据页，两者的关系是什么呢？
表和行是逻辑概念，逻辑层面无需关心物理层面的实现。表空间、数据页就属于物理概念，在物理层面上，一个表里的数据都是放在一个表空间中，表空间由一堆磁盘上的数据文件组成，而数据文件是由一个一个的数据页组成的。

### 说下 Mysql 的预读机制？
当从磁盘加载一个数据页时，会连带着把跟它相邻的数据页也加载到 bufferPool 中
### 哪些情况下会触发mysql的预读机制？
(1)mysql配置中有一个参数:"innodb_read_ahead_threshold"，默认值为56，意思是如果顺序访问了一个区里的多个数据页
，访问的数据页数量超过这个阈值，就会触发预读机制将下一个相邻区中的所有数据页全部加载到bufferPool里
(2)如果bufferPool里缓存了一个区里的连续13个数据页，而且这些数据页被频繁访问，就会触发预读机制，将整个区的其他数据页都加载到bufferPool里。
这个机制通过配置中参数"innodb_random_read_ahead"控制，默认是off
### 为什么mysql要设计这个预读机制？

### MySQL的bufferPool中的LRU链表结构:
由于简单LRU链表在mysql预读和全表查询两种情况下存在的缓存页热度失真的情况，mysql在设计lru链表时采用的是
冷热数据分离的思想。整个链表分为两部分，一部分是冷数据，一部分是热数据，冷数据比例由参数"innodb_old_blocks_pct"控制，默认是37，也就是说冷数据
占37%。第一次从磁盘加载到bufferPool的缓存页会被放在冷数据区的链表头部

### 什么时候会将冷数据区的缓存页移动到热数据区？
mysql设定了一个规则，一个数据页从磁盘加载到bufferPool 1s 后被访问才会被移动到热数据区链表头，1s内的还留在冷数据区。
可以修改mysql配置参数"innodb_old_blocks_time"默认值为1000，也就是1000毫秒。

### 为什么要使用基于冷热数据分离的LRU链表？主要是为了解决什么问题？
为了解决使用普通LRU链表时在预读机制和全表查询场景造成的缓存热度失真。
这样预读或者全表扫描加载的数据页，大部分会在1s内访问后之后再也不访问了，这种缓存页会留在冷数据区，而频繁访问的
缓存页在热数据区中。当淘汰缓存时，就会优先淘汰冷数据区尾部的缓存页，避免了可能会把热数据淘汰掉

### LRu链表尾部的缓存页，是如何淘汰他们刷入磁盘的？
由后台线程在mysql不忙的时候去把flush链表的缓存页都刷入磁盘

## Mysql是如何把lru链表的热数据区优化到极致的？
按之前的规则，在从磁盘加载到冷数据区，只有1秒后被访问的数据，才会被移动到热数据区的链表头。在热数据区中的数据，如果每次一个缓存页被访问都需要移动到热数据区的链表头，会造成频繁移动，会影响性能。
所以mysql把热数据区分为两部分，前1/4和后3/4。前1/4的缓存页被访问是不会被移动到链表头的，只有后3/4的缓存页被访问才会被移动到链表头，这样就尽可能的减少了链表中的节点移动了。

### bufferPool在访问的时候需要加锁吗？
必然需要。由于bufferPool的本质是一块内存数据结构，由一大堆的缓存页和描述数据组成，然后加上各种链表(free、flush、lru)来辅助他的运行。
但是当mysql收到请求时是用多线程处理的，所以是多线程并发访问BufferPool必然需要加锁。先让一个线程加载数据页到缓存页，然后
更新free链表，更新lru链表，然后释放锁，接着才轮到下一个线程来执行一系列操作

### 多线程并发访问bufferPool并且还需要加锁，数据库的性能还好吗？
即使就一个bufferPool，即使多个线程排队加锁来串行执行，由于操作发生在内存里，并且更新free、flush、lru链表等都是基于基本都是微秒级别的，所以性能也差不了哪去。

### 多线程并发访问bufferPool并且还需要加锁，数据库的性能还好吗？
即使就一个bufferPool，即使多个线程排队加锁来串行执行，由于操作发生在内存里，并且更新free、flush、lru链表等都是基于链表进行一些指针操作，基本都是微秒级别的，所以性能也差不了哪去。
但是由于有的线程拿到锁后，会需要从磁盘中读取数据页到缓存页中，这里发生了磁盘io，比较耗时，自然会影响性能。

### 如何改进bufferPool中并发加锁中发生IO导致的性能下降？
生产环境可以设置多个bufferPool来优化整体并发能力。
Mysql默认规则是如果给bufferPool分配的内存小于1GB，那么最多只会分配给1个bufferPool。如果mysql使用的机器内存很大，必然会给bufferPool分配较大的内存，比如给BufferPool分配8G内存，此时可以设置多个BufferPool，每个bufferPool设置为2g内存
```
[server]
innodb_buffer_pool_size=8589934592
innodb_buffer_pool_instances=4
```
设置后mysql运行时有4个bufferPool，每个bufferPool只管理一部分的缓存页和描述数据块，可以使用多个线程来并发访问不同的bufferPool，因为多个线程在不同的bufferPool中加锁然后执行自己的操作，可以使mysql性能成倍提升。因此在生产环境通过设置多个bufferPool来优化高并发访问性能是mysql一个很重要的优化技巧

### bufferPool这种大块头可以在运行期间动态调整大小吗？
可以。mysql把bufferPool实现为由很多chunk组成，chunk大小由配置参数"innodb_buffer_pool_chunk_size"控制，默认值为128MB。一个2GB的bufferPool由16个128MB的chunk组成，每个bufferPool里的多个chunk共享一套free、flush、lru链表。有了这套chunk机制，就可以动态调整bufferPool大小了。当要扩大内存时，只需要申请一系列大小为128MB的chunk就可以了，只要每个chunk是连续的128MB内存即可，然后把申请到的chunk分配给bufferPool

### 我们写入数据库的一行数据在磁盘上是如何存储的？
由于存储数据要节约空间，所以不能使用java序列化对象的方式，因此在mysql的innodb存储引擎中是把很多行数据都紧紧挨在一起的方式存储的，这里引入了一个数据页的概念，也就是把数据组织成一页一页的概念，每页16kb，每次从磁盘加载数据到内存是至少加载一页数据进去的，甚至是多页数据
变长字段是如何存储的？
null值是如何存储的？

### 数据库返回“too many connections”，如何定位？
返回"too many connection"表示数据库的连接池里已经有太多连接了，无法继续创建新连接了。数据库内部有一个连接池，java系统里的数据库连接池里的连接和数据库内部连接池的连接一一对应。

* 实际案例排查思路：64g大内存机器上部署mysql，有两个java实例连接mysql，每个java实例配置的数据库连接池大小为200，当两台java实例启动时报“too many connections”，说明数据库当前建立的连接少于400个，检查my.cnf文件中配置的max connections为800，然后登录到mysql，使用命令“show variables like 'max_connections'”显示当前连接数为214个，这是由于底层linux操作系统把每个进程可以打开的文件句柄数限制为了1024额所以导致mysql最大连接数为214。

* 解决方法：在linux上输入：

  ```
  ulimit -HSn 65535  修改每个进程可以打开的最大文件句柄数为65535，
  ```

  然后使用下面命令查看是否修改成功：

  ```
  cat /etc/security/limits.conf
  cat /etc/rc.local
  ```

  查看是否修改成功查看是否修改成功


### redo log存在的意义？
当事务提交成功时，mysql绝对会保证这个事务所做的修改都记录在了redo log中，才会给你返回成功，这时即使mysql宕机也不怕了。mysql宕机重启后会根据redo log中记录的事务所做过的修改，重新从磁盘加载然后在bufferpool里都执行一遍，就可以恢复当时事务对缓存页做的修改了，然后再找时机把缓存页刷入磁盘

### redo log长什么样？
本质上就是记录的在某个表空间的某个数据页的某个偏移量修改了几个字节的值。
实际记录的是表空间号＋数据页号＋偏移量＋修改几个字节的值＋具体的值

### redo log是直接一条一条写入文件的吗？(redo log写磁盘的过程)

redo log不是一条一条直接往磁盘里写的，

之前了解过mysql的innodb引擎存储数据并不是单行存储的，而是以数据页为最小单位来存储的。

同样redo log也不是由一行一行的数据组成的，redo log是以redo log block为最小单位来存储的，一个redo log block可能记录了多个单行日志

redo log的确是存在磁盘上的文件，这个文件是由很多个redo log block 组成的，

如果依次在磁盘文件的末尾追加不停的写字节数据，就是磁盘顺序写。如果在多个文件中找出一个文件再修改这个文件的几个字节的内容，就是磁盘随机写

### redo log是如何通过redo log buffer这个内存缓冲数据结构写入到磁盘文件的

首先，一组事务里的多条redo log是作为一个redo log group存在的，先暂存在内存缓冲中，等事务执行完成时，把整个redo log group写入内存的一块叫做redo log buffer的内存区域，然后才会把redo log buffer中的redo log block写入redo log文件的。这个区域是mysql启动时向操作系统申请的一块连续内存。和bufferPool类似，mysql会把redo log buffer划分成很多个空的 redo log block。redo log buffer默认是16MB，也可以通过参数“innodb_log_buffer_size”更改。如果redo log buffer里所有的block都写满了，就会强制将block刷入磁盘中。而如果一个事务比较大， 所形成的redo log超过了一块block，是可以存放在两个block中的。

### redo log buffer中的redo log block到底什么时候可以写入磁盘？

(1)如果写入redo log buffer的日志占据redo log buffer总容量的一半，也就是超过8MB，就会把他们刷入磁盘。这种场景在mysql瞬间执行大量高并发sql时可能会出现，1s内产生超过8MB的redo log，此时会立即把redo log刷入磁盘

(2)一个事务提交时，必须把事务的redo log所在的redo log block刷入磁盘。这样才能保证事务提交后事务所修改的数据不会丢失，宕机后可以根据redo log来重做恢复(redo log写入磁盘时是先写入操作系统的os cache中，再写磁盘的，要想保证数据绝对不丢，需要配置一个参数，在提交事务把redo log刷入磁盘文件的os cache后，还得强行从os cache刷入物理磁盘才能保证绝对不丢。)

(3)后台线程定时刷新。后台有一个线程会每隔1s把redo logbuffer里的redo log block刷入磁盘。一般都会通过第二个场景刷入磁盘，只是一种补偿措施

(4)mysql关闭时，redo log block会全部刷入磁盘

### redo log写满了怎么办？

redo log的存放目录可以通过参数"innodb_log_group_home_dir"来指定。通过参数"innodb_log_files_in_group"可以指定日志文件数量，默认有两个redo log文件，分别为ib_logfile0 和ib_logfile1。通过参数“innodb_log_file_size”来指定每个redo log文件的大小，默认是48MB。先写第一个文件，写满了再写第二个，如果第二个也写满了，就继续写第一个来覆盖第一个日志文件原有的redo log。96MB足够存上百万条redo log了

### undo log也就是回滚日志有什么作用？undo log的工作原理是什么？

undo log用于事务回滚的场景。undo log记录的是当前事务所有执行操作的反操作，事务操作无非是增删改，那undo log就记录了这三种操作各自的反操作。如果事务执行了一个insert操作，undo log里就记录一个delete刚刚insert的记录的主键的操作，如果是delete操作，则undo log就记录insert语句；如果是update操作，undo log就把原值记录下来。

### insert语句的undo log回滚日志长什么样？

==insert语句的undolog类型为TRX_UNDO_insert_rec==

一条insert语句的undo log语句是这样组成的:undo log日志开始位置 | 主键<列长度，列值> | 表id | undo log日志编号 | undo log日志类型 | undo log日志结束位置

### 已经讲完了MySQL的BufferPool机制、redo Log机制、undo log机制，应该对平时执行增删改查语句的实现原理有一定的深入理解

(数据库中多个事务并发执行可能带来的问题)多个事务对缓存页里的同一条数据进行更新或者查询，会产生哪些问题呢？脏写、脏读、不可重复读、幻读

脏写:两个事务在没提交的情况下，都修改同一条数据，结果一个事务回滚了，把另一个事务修改的值给撤销了

脏读:一个事务修改了一条数据还没提交呢，就被另一个事务读到了修改的数据，然后第一个事务回滚了导致第二个事务读到了脏数据 

无论是脏读还是脏写，原因都是一个事务读取或者更新了另一个事务还没有提交的数据造成的

不可重复读:一个事务两次查询同一条数据得到的查询结果不同，也就是说在一个事务的两个查询中中间穿插了另一个事务对记录修改后成功提交。不可重复读不算什么大问题，到底有没有不良影响取决于使用场景能不能接受，但在sql标准中，也就是在数据库实现的角度不可重复读是被定义为一种数据库的问题

幻读:就是幻行，两次范围查询中后一次查询读到了比第一次查询多的记录

### SQL标准中对事务的4个隔离级别是如何规定的？

针对数据库的多事务并发带来的几个问题，所以sql标准规定了事务的4种隔离级别来解决这些问题。

* 第一个读未提交隔离级别。不允许发生脏写，也就是说不允许两个事务在没提交的情况下去更新同一行数据。允许发生脏读、不可重复读、幻读
* 第二个是读已提交级别。不允许发生脏写和脏读，由于其他事务未提交的记录是无法被另一个事务读到的，所以就避免了脏读。同时允许发生不可重复读和幻读
* 第三个是可重复读级别。不允许发生脏写、脏读、不可重复读。由于一个事务的多次查询即使数据被其他事务修改了，他也是读不到的，所以查询结果始终没有变化，因此避免了脏写、脏读、不可重复读
* 第四个是串行化级别。不允许事务并发执行，只能一个一个排队执行，所以能避免一切并发带来的问题

### MySQL是如何支持SQL标准中的4种隔离级别的？

mysql支持sql标准中的4种隔离级别，除此之外，mysql默认事务隔离级别为可重复读，sql标准下这个隔离级别是可以发生幻读的，而mysql对可重复读隔离级别的实现能做到避免幻读！总之，在mysql可重复读隔离级别下，能做到事务之间互相完全不影响

### 理解MVCC机制的前奏，undo log版本链是什么？

mysql的默认隔离级别可重复读能做到多个事务并发执行之间互不影响，依靠的就是经典的MVCC多版本并发控制机制来做到的。而mvcc机制是由undo log版本链和readView来实现的。

undo log版本链:表中的每条数据都有两个隐藏字段，一个是trx_id，表示最近一次更新这条数据的事务id；一个是roll_pointer，记录的是这条数据在被trx_id这个事务更新之前的undo log指针。

因为mysql数据库已经根据sql标准去在任何级别下避免了脏写，所以多个事务是串行修改一行数据的，并且修改时会更新隐藏字段trx_id和roll_pointer

#### 基于undo log版本链是如何实现readView机制的？

readView，就是执行事务时，会生成一个readView，读视图，比较关键的参数有4个:

* m_ids:此时有哪些事务正在执行还没有提交
* min_trx_id:m_ids里的最小值
* max_trx_id:mysql下一个要生成的事务id，也就是最大事务id
* creator_trx_id:当前事务的id

通过记录undo log多版本链条，再加上事务开启时生成的一个readView，然后事务中的查询就根据readView进行判断，去选择读取哪个版本的数据。这套机制能保证当前事务只能读到事务开启前已经提交的事务更新的值，还有本事务更新的值。 当本事务开启后，其他事务更新了值无论是否已提交，本事务都不会读到修改的值。 通过这套机制实现了多个事务并发执行时的数据隔离

#### 读已提交级别是如何基于readView机制实现的？

读已提交隔离级别的意思就是，在本事务运行期间，只要其他事务修改后提交了，那本事务就可以读取其他事务所提交的数据。所以这样会发生不可重复读、幻读问题。

所以对于读已提交级别，是每次发起新查询都会重新生成一个readView

#### 可重复读级别是如何基于readView机制实现的？

事务开启后，生成一个readView，然后在整个事务查询过程中都使用这一个readView去处理数据可见性

#### 梳理:MySQL中的多事务并发运行的隔离原理，也就是MVCC机制的运行过程

用undo log版本链，加上readView规则，来判断数据的可见性，主要是readView在读已提交和可重复读两个级别下的判断条件

#### 多个事务并发更新同一行数据，数据库是怎么避免脏写的？

简单说，脏写是依靠锁机制把并发更新做串行化处理，避免并发更新。当事务A要对一行数据更新时，先检查下是否有其他事务对这行数据加了锁，如果没有则会创建一个锁，锁里面包含本事务的trx_id和等待状态false(已经获取锁)，然后把这把锁和这行数据做关联(在内存中)。这是事务B要修改这行记录检查是否有锁，发现这行数据已被加锁，事务B也生成一个锁数据结构，等待状态为true。当A更新完成后，会把锁释放然后去找是否有其他事务对这行数据加锁，发现了事务B加的锁，然后把事务B的锁的等待状态改为false，然后唤醒B继续执行。

#### MySQL中的共享锁和独占锁

多个事务并发更新同一行数据时加的是行级别独占锁。

mysql也支持共享锁，语法为:select * from table lock in share mode

mysql也支持独占锁，语法为:select * from table for update

* 共享锁和共享锁不互斥，可以同时加。
* 共享锁和独占锁互斥，不能同时加。
* 独占锁和独占锁互斥，不能同时加

一般开发业务系统时， 很少在数据库去加共享锁、行锁，而是用基于zookeeper/redis的分布式锁来控制业务的锁逻辑

#### 数据库中哪些操作会导致在表级别加锁？



#### 案例实战:线上数据库不定时的性能抖动优化

* 不是之前讲过的数据库锂电池充放电问题
* 第一个原因可能是bufferPool满了，而执行的是查询语句，需要将大量数据缓存到bufferPool中，导致bufferpool中大量的脏页需要刷入磁盘，刷磁盘太慢了导致这期间的查询语句执行很慢造成性能抖动
* 第二个原因可能是redo log日志文件全部被写满了，这时候也会触发刷脏页。因为需要回到第一个redo log文件开始覆盖写，而在覆盖写之前需要把第一个redo log里的缓存页刷入磁盘

上面两个场景都是由于刷脏页导致的性能抖动。解决方法就是尽可能优化mysql参数。比较核心的两个点: 第一是降低缓存页刷入磁盘的频率，第二是提高缓存页刷入磁盘的速度

降低刷入频率:部署数据库的机器使用ssd固态硬盘，因为随机io很高。使用固态硬盘后还需要设置参数"innodb_io_capacity"来告诉数据库使用多大的IO速率把缓存页刷入磁盘。还有一个参数是"innodb_flush_neighbors"表示在将缓存刷入磁盘时，可能会把缓存页相邻的其他缓存页也刷入磁盘，但是这样会导致flush时需要刷新的缓存页过多，如果使用SSD，可以把"innodb_flush_neighbors"参数设置为0，表示禁止刷相邻缓存页，这样就可以减少每次刷盘的缓存页了








































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































