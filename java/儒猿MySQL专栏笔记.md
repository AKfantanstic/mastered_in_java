## "update user set name = 'XXX' where id = 10" 的更新过程？
先把要更新的这行记录从磁盘文件加载到缓冲池，然后对这行记录加锁后将这行数据的旧值记录到undo日志中。然后先更新内存缓冲池中的记录，然后将更新写入到redo log buffer中，redo log buffer是一块内存缓冲器，redo log buffer 有3种策略将数据写入磁盘中，
通过innodb_flush_log_at_trx_commit来配置。写完redo 
log后会将binlog按刷盘策略来写入磁盘写完binlog后，进入事务的最终提交阶段，会把本次更新对应的binlog文件名和本次更新内容记在binlog文件中的位置，都写入到redo log中，同时在redo 
log文件中写入一个commit标记，整个事务完成。commit标记用于保持redo log和binlog的一致性，假如刚刚将redolog写入磁盘文件，mysql宕机了，此时机器恢复后，由于redo log中没有commit标记，所以mysql判定此次事务不成功。假如将binlog写入磁盘了，然后mysql宕机了，此时同样会因为redo log中没有commit标记，认定此次事务不成功，必须是在redo log中写入commit标记后，才算此时事务提交成功，这时redolog 中有本次更新对应的日志，binlog中也有本次更新对应的日志，这时redo log和binlog是完全一致的。最后由后台IO线程将脏页刷回磁盘。
* 当参数为0时，提交事务时不会将redo log buffer里的数据写入磁盘，这种情况下当mysql宕机事务数据会丢失。
* 当参数为1时，提交事务时必须将redo log buffer中数据写入磁盘，也就是说只要事务提交成功，redo log一定会写入磁盘。此时mysql宕机事务数据也不会丢失，因为即使磁盘数据没有改变，但是redolog磁盘文件已经记录了，当mysql重启后会根据redo log去恢复内容。
* 当参数为2时，提交事务时将redo log写入磁盘文件对应的 os cache里，而不是直接写入磁盘文件，有可能1秒后才会把os cache里的数据写入磁盘。这种情况下，当提交事务后，redolog仅仅停留在os 
cache里没有实际写入磁盘文件，此时如果机器宕机，还是会丢失数据
* 对于redo log的刷盘策略，通常设置为1。也就是提交事务时，redo log必须刷入磁盘文件里，对于数据库这样的严格系统，这样可以保证事务提交后，数据绝不会丢失

## binlog的刷盘策略？
用sync_binlog参数来控制binlog的刷盘策略。
* 默认值是0。意思是把binlog写入磁盘时，不直接写入磁盘文件而是写入os cache内存中，此时宕机，os cache中binlog会丢失
* 参数为1。会强制在事务提交时，将binlog写入磁盘文件里。这样即使提交事务后机器宕机，binlog也不会丢。

生产经验:
Java应用系统部署在4核8G机器上，每秒可以抗500左右并发量。
一般8核16G的机器部署MySQL数据库，每秒种可以抗1、2K并发
对于16核32G的机器部署MySQL数据库，每秒可以抗2、3k并发
# 数据库压测需要关注的相关性能指标:
IO相关:
(1)IOPS:指的是机器随机IO并发处理能力，比如200IOPS意思就是说每秒可以执行200个随机IO读写请求。
当在内存bufferPool写入脏数据后，需要后台IO线程在机器空闲时刷回到磁盘，这是一个随机IO的过程。如果IOPS过低，会导致内存里脏数据刷回磁盘的效率太低
(2)吞吐量:指的是机器磁盘每秒可以读写多少字节
当执行sql提交事务时需要将大量redo log等日志写入磁盘，写入redolog一般是一行一行顺序写入，不会进行随机读写，一般SSD顺序写吞吐量可达到每秒200MB
，对于承载高并发来说，SSD磁盘吞吐量不是瓶颈
(3)latency:指的是向磁盘写入一条数据的延迟。当执行sql和提交事务时，需要将redo log顺序写到磁盘，如果写入延迟过高会影响数据库的sql执行性能。写入延迟越低，执行sql的事务的速度就越快，数据库性能就越高
(4)CPU负载:压测中如果CPU负载特别高，就说明已经到达瓶颈，不能继续压测了
(5)网络负载:关注每秒钟网卡会输入多少MB数据，会输出多少MB数据，当到达网络带宽最大值时说明已经出现瓶颈了，就不能再继续压测了
(6)内存负载:如果内存占用过高，也说明不能继续压测了

## 数据库压测工具 sysbench 使用方法:
```
使用如下命令设置yum repo仓库，然后使用yum来安装sysbench
curl -s https://packagecloud.io/install/repositories/akopytov/sysbench/script.rpm.sh|sudo bash
sudo yum -y install sysbench
sysbench --version  
看到sysbench版本号说明安装成功

然后在数据库建好测试库名字叫test_db,然后创建测试账号，然后基于sysbench构建20个测试表，每个表100万条数据，使用10个并发线程对数据库发起访问，连续访问300秒，也就是压测5分钟。
先基于sysbench构造测试表和测试数据:
sysbench --db-driver=mysql --time=300 --threads=10 --report-interval=1 --mysql-host=192.168.11.113 --mysql-port=3306 --mysql-user=root --mysql-password=123456 --mysql-db=test_db --tables=20 --table_size=1000000 oltp_read_write --db-ps-mode=disable prepare

(1)--db-driver=mysql: 基于mysql驱动去连接mysql数据库，如果是oracle、sqlServer可以更换
(2)--time: 连续压测时间，单位秒
(3)--threads=10: 10个线程并发访问
(4)--report-interval=1: 每隔1秒输出压测情况
(5)--mysql-host=127.0.0.1 --mysql-port=3306 --mysql-user=test_user --mysql-password=test_user:指定mysql连接相关信息
(6)--mysql-db=test_db --tables=20 --table_size=1000000: 指定压测数据库，构造20个测试表，每个表100万条测试数据
(7)oltp_read_write: 执行oltp数据库的读写测试
(8)--db-ps-mode=disable: 禁用ps模式
(9)prepare: 按照上面的命令去构造测试数据
   run:运行压测
   cleanup:清理测试数据
   
测试数据库综合读写TPS，使用oltp_read_write模式:
sysbench --db-driver=mysql --time=300 --threads=20 --report-interval=1 --mysql-host=192.168.11.113 --mysql-port=3306 --mysql-user=root --mysql-password=123456 --mysql-db=test_db --tables=20 --table_size=1000000 oltp_read_write --db-ps-mode=disable run

测试数据库的只读性能，使用oltp_read_only模式(将oltp_read_write改为oltp_read_only)

测试数据库的删除性能，使用oltp_delete模式

测试数据库的更新索引字段性能，使用oltp_update_index模式

测试数据库的更新非索引字段的性能，使用oltp_update_non_index模式

测试数据库的写入性能，使用oltp_write_only模式

[ 116s ] thds: 20 tps: 340.03 qps: 6809.60 (r/w/o: 4760.42/1369.12/680.06) lat (ms,95%): 125.52 err/s: 0.00 reconn/s: 0.00
每秒压测报告解读:
(1)thds:20,压测线程数
(2)tps:340.03，每秒执行340.03个事务
(3)qps:6809.60，每秒执行6809.60个请求
(4)r/w/o:760.42/1369.12/680.06 : 每秒6809.60个请求中，有760.42个读请求，1369.12个写请求，680.06个其他请求。也就是对QPS的拆解
(5)lat(ms,95%):125.52 :95%请求的延迟在125.52毫秒以下
(6)err/s:0.00 reconn/s:0.00 :每秒有0个请求失败，发生了0次网络重连

总压测报告:
SQL statistics:
    queries performed:
        read(压测期间执行的总读请求数): 1275694
        write(总写请求数):            364484
        other(总其他请求数):          182242
        total(总请求数):              1822420
    transactions:                        91121  (303.60 per sec.)
    queries:                             1822420 (6072.00 per sec.)
    ignored errors:                      0      (0.00 per sec.)
    reconnects:                          0      (0.00 per sec.)

General statistics:
    total time:                          300.1328s
    total number of events(总执行事务数):  91121

Latency (ms):
         min(请求最小延迟):  12.34
         avg(请求平均延迟):  65.85
         max(请求最大延迟):  1494.97
         95th percentile(95%请求延迟时间): 123.28
         sum:  6000298.15

Threads fairness:
    events (avg/stddev):           4556.0500/20.80
    execution time (avg/stddev):   300.0149/0.03
```

# Buffer Pool:
是数据库中一块基于内存的组件，核心是通过使用内存而不是直接使用硬盘来提高访问速度。Java系统对数据库执行增删改查请求主要就是对这个内存组件中的缓存数据执行的

### 如何配置buffer pool大小？
默认大小下为128MB，有点偏小，对于16核32G机器，可以给BufferPool分配个2GB内存。通过修改配置参数:innodb_buffer_pool_size=2147483648

bufferPool内部结构:buffer_pool中包含多个缓存页，同时每个缓存页还有一个描述数据。当数据库启动时，会按照bufferPool的大小再稍微加大一点去向操作系统申请一块内存区域，作为bufferPool内存区域。然后按照默认缓存页的16KB大小以及800个字节左右的描述数据大小，将整个bufferPool划分成一个一个的缓存页和一个一个的缓存页对应的描述数据。每个描述数据块都是free链表的一个节点，free链表是一个双向链表

## 如何查询一个数据页是否在bufferPool中呢？
数据库中有一张hash表，使用表空间+数据页号作为key，缓存页的地址作为value。当要使用一个数据页时，通过“表空间号+数据页号”作为key去hash表中查询，如果value为空说明缓存页不存在，则需要从磁盘中读取数据页到缓存页中

## 如果bufferPool中的缓存页不够了怎么办？
bufferPool中维护了一个由缓存页的描述数据块作为结点的LRU链表，最近被访问过的数据块一定在LRU链表的头部。当缓存页满了时，就会找出最近最少被访问的缓存页，将这个缓存页刷入磁盘



























































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































