## 分布式事务: 单体应用靠单个数据库的事务机制来保证数据的一致性。分布式应用需要用分布式事务来保证每个数据库中数据的一致性,从而保证整体数据的一致性
主要有以下5种方案:
* XA 方案
* TCC 方案
* 本地消息表
* 可靠消息最终一致性方案
* 最大努力通知方案

### XA 方案: 两阶段提交协议
用一个全局的事务管理器来负责协调各个数据库的事务提交
* 阶段1：全局的事务管理器向各个数据库发出准备消息。各个数据库需要在本地把一切都准备好，执行操作，锁住资源，记录redo/undo
日志，但是并不提交，进入一种时刻准备提交或回滚的状态，然后向全局事务管理器报告是否准备好了。  
ps: (先把事务都执行完成，但是不提交)
* 阶段2
：如果所有的数据库都报告说准备好了，那么全局的事务管理器就下命令：提交！这时候各个数据库才真正提交。由于之前已经万事俱备，只欠东风。所以只需要快速完成本地提交即可如果有任何一个数据库报告说没准备好，那么全局的事务管理器就下命令：放弃！这时候各个数据库执行回滚操作，并且释放在阶段1锁住的各种资源。
ps: (事务提交或回滚)

**使用场景**：这种分布式事务方案比较适合单块应用中跨多个库的分布式事务，而且因为严重依赖数据库层面来搞定复杂事务，效率很低，绝对不适合高并发的场景。  
实现方式：Spring + JTA  
**缺点**：JTA 的分布式事务伴随大量节点的通信交换，协调者要确定其他节点是否完成，加上网络带来的超时，导致 JTA 性能低下  
**优点**：JTA 目的是为了保证强一致性  

### TCC 方案: Try、Confirm、Cancel
* **Try 阶段( 预留资源 )**：对各个服务的资源做检测以及对资源进行锁定或者预留。(冻结银行资金)
* **Confirm 阶段( 执行实际操作 )**：在各个服务中执行实际的操作。(扣款并转账)
* **Cancel 阶段( 进行补偿回滚 )**：如果任何一个服务的业务方法执行出错，那么这里就需要进行补偿，就是对已经执行成功的业务逻辑进行回滚操作。（执行补偿代码进行回滚）
使用场景：一般来说跟钱相关的，跟钱打交道的，支付、交易相关的场景，我们会用 TCC，严格保证分布式事务要么全部成功，要么全部自动回滚，严格保证资金的正确性，保证在资金上不会出现问题。而且最好是你的各个业务执行的时间都比较短。
缺点：需要自己手写回滚逻辑或者是补偿逻辑，导致业务代码难以维护
优点：能保证强一致性

### 本地消息表：
消息生产方，需要额外建一个消息表，并记录消息发送状态。消息表和业务数据要在一个事务里提交，也就是说他们要在一个数据库里面。然后消息会通过MQ发送到消息的消费方。如果消息发送失败，会进行重试发送。
消息消费方，需要处理这个消息，并完成自己的业务逻辑。此时如果本地事务处理成功，表明已经处理成功了，如果处理失败，那么就会重试执行。如果是业务上面的失败，可以给生产方发送一个业务补偿消息，通知生产方进行回滚等操作。
生产方和消费方定时扫描本地消息表，把还没处理完成的消息或者失败的消息再发送一遍。如果有靠谱的自动对账补账逻辑，这种方案还是非常实用的。

缺点：严重依赖于数据库的消息表来管理事务，定时任务，消息表与业务系统严重耦合

### 可靠消息最终一致性方案:
干脆不要用本地的消息表了，直接基于 MQ 来实现事务。比如阿里的 RocketMQ 就支持消息事务。
A 系统先发送一个 prepared 消息到 mq，如果这个 prepared 消息发送失败那么就直接取消操作别执行了；
如果这个消息发送成功过了，那么接着执行本地事务，如果成功就告诉 mq 发送确认消息，如果失败就告诉 mq 回滚消息；
如果发送了确认消息，那么此时 B 系统会接收到确认消息，然后执行本地的事务；
mq 会自动定时轮询所有 prepared 消息回调你的接口，问你，这个消息是不是本地事务处理失败了，所有没发送确认的消息，是继续重试还是回滚？一般来说这里你就可以查下数据库看之前本地事务是否执行，如果回滚了，那么这里也回滚吧。这个就是避免可能本地事务执行成功了，而确认消息却发送失败了。
这个方案里，要是系统 B 的事务失败了咋办？重试咯，自动不断重试直到成功，如果实在是不行，要么就是针对重要的资金类业务进行回滚，比如 B 系统本地回滚后，想办法通知系统 A 也回滚；或者是发送报警由人工来手工回滚和补偿。
这个还是比较合适的，目前国内互联网公司大都是这么玩儿的，要不你举用 RocketMQ 支持的，要不你就自己基于类似 ActiveMQ？RabbitMQ？自己封装一套类似的逻辑出来，总之思路就是这样子的。

### 最大努力通知方案:
* 系统 A 本地事务执行完之后，发送个消息到 MQ
* 这里会有个专门消费 MQ 的最大努力通知服务，这个服务会消费 MQ 然后写入数据库中记录下来，或者是放入个内存队列也可以，接着调用系统 B 的接口；
* 要是系统 B 执行成功就 ok 了；要是系统 B 执行失败了，那么最大努力通知服务就定时尝试重新调用系统 B，反复 N 次，最后还是不行就放弃。


### 最大努力通知方案 和 本地消息表方案的区别？
最大努力通知，就是多通知几次，假设5次还不行，就不通知了；而本地消息表是一直通知，直到消息状态为已确认为止

### 你们公司是如何处理分布式事务的？
我们某某特别严格的场景，用的是 TCC 来保证强一致性；然后其他的一些场景基于阿里的 RocketMQ 来实现分布式事务。
你找一个严格资金要求绝对不能错的场景，你可以说你是用的 TCC 方案；如果是一般的分布式事务场景，订单插入之后要调用库存服务更新库存，库存数据没有资金那么的敏感，可以用可靠消息最终一致性方案。
友情提示一下，RocketMQ 3.2.6 之前的版本，是可以按照上面的思路来的，但是之后接口做了一些改变
当然如果你愿意，你可以参考可靠消息最终一致性方案来自己实现一套分布式事务，比如基于 RocketMQ。

### 针对电商核心交易链路，你们是怎么设计分布式事务技术方案的？
**分布式事务方案中的 TCC 和 可靠消息最终一致性方案，在生产中是最常用的。**而最大努力通知方案、Sega、XA，这几种方案在生产中用的不多

对于下面场景的分布式事务技术方案分析:
订单服务 -> 创建订单
-> 库存服务 -> 扣减库存
-> 积分服务 -> 增加积分
-> 仓储服务 -> 通知发货

可以把订单服务、库存服务、积分服务 -> 绑定成一个 TCC 事务，如果积分服务报错，就会撤销刚才创建的订单，回滚刚才扣减的库存。

仓储服务通知发货没必要绑定到TCC事务中，仓储服务使用可靠消息最终一致性方案，通过将消息发送给可靠消息中间件，由消息中间件来保证消息一定会发给仓储服务然后通知发货，如果这个过程中消息发送失败可以由可靠消息中间件来保证不停的重试投递消息

### 对于 TCC 事务、最终一致性事务的技术选型，你们是怎么做的？如何调研的？
* TCC事务: 阿里开源的分布式事务框架 seata ,经历过阿里生产环境大量考验的一个框架，支持 dubbo、spring cloud两种服务框架
* 最终一致性事务:
>1. 可靠消息最终一致性，如果使用ActiveMQ或者RabbitMQ，需要自己封装一个可靠消息服务，收到消息后会尝试投递到mQ上，如果投递失败就重试投递
。如果消费成功了必须回调一个接口来通知消息处理成功，如果一段时间后发现消息还是没有处理成功，此时会再次
投递消息到mQ上去。此方案需要在本地数据库存放一些信息，然后基于ActiveMQ\RabbitMQ来实现消息的异步投递和消费
>2. 使用RocketMQ作为MQ中间件，提供了分布式事务支持，中间件把可靠消息服务需要实现的功能逻辑都做好了

### 作业:你们公司的核心链路是否有事务问题？ 
你自己的系统，核心链路是否存在数据不一致的问题，分布式事务的技术选型？如果要设计分布式事务方案，如何设计？

### 在搭建好的电商系统里，落地开发对交易链路的TCC分布式事务方案
基于seata去用分布式事务，必须先独立部署seata-server

### 能说一下一个TCC分布式事务框架的原理吗？
seata原理

### 现有的 TCC 事务方案的性能瓶颈在哪里？能支撑高并发交易场景吗？如何优化？
* byteTCC框架，需要在mysql中创建表，然后基于表中数据进行状态更新
* seata框架，核心链路中的每个服务都需要跟TC这个角色进行频繁的网络通信，带来性能开销。如果一个请求不引入分布式事务可能只需要100ms，引入分布式事务后可能需要耗费200ms。
而所有微服务需要上报分支事务的状态给tc，并且seata-server需要选择基于哪种存储来存放这些分布式事务日志或者状态信息，一般是选择磁盘文件、MySQL。
在高并发场景下也需要对seata-server进行扩容，部署多台机器。这时如果用一个数据库来存放分布式事务的日志和状态的话，数据库也会有压力，需要对tc背后的数据库进行分库分表来抗更
高的并发压力

### 作业:如果对自己的系统核心链路落地TCC事务，应该如何落地实现？
参考seata的sample，尝试把seata分布式事务框架整合到springcloud技术架构里去，成功跑起来

### 你了解rocketMQ对分布式事务支持的底层实现原理吗？
RocketMQ来实现可可靠消息最终一致性事务方案:
>1. producer向RocketMQ发送一个half-message，RocketMQ返回一个half-message success的响应给producer，这时候就形成了一个half-message
了，此时这个message是不能被消费的。注意这个步骤可能会因为网络等原因失败，有可能producer没有收到rocketMQ返回的响应，这时需要producer
重新发送half-message，直到一个half-message成功创建
>2. producer在本地数据库执行相关操作，然后根据数据库操作的结果发送commit/rollback给RocketMQ，如果本地数据库执行成功则发送一个commit，这时消息变为可以被消费的；如果
本地数据库执行失败，就发送一个rollback来废弃之前的half-message。注意这个步骤可能会失败，因为producer可能会由于网络原因没成功发送commit/rollback给rocketMQ，此时RocketMQ
会在一段时间后发现一直没收到message的commit/rollback，就会回调此服务提供的一个接口
>3. 在这个接口中需要自己写逻辑去检查之前执行的本地数据库操作是否成功了，然后返回commit/rollback给RocketMQ，
>4. 只要message被commit，下游的服务就可以消费到这个消息，此时还需要结合ack机制，也就是下游消费者必须在消费成功后返回ack给RocketMQ才能被认为消息成功，否则一旦处理失败没有返回ack
，则必须让rocketMQ重新投递消息给其他consumer

### 在搭建好的电商系统里，如何基于RocketMQ最终一致性事务进行落地开发？
在自己本地部署一个单机版的rocketMQ，参考RocketMQ官网的sample，做实验，实际发送一下消息，回调接口，一个是事务消息，一个是消费者ack

### 如果公司没有RocketMQ中间件，那你们如何实现最终一致性？
自己写一个可靠消息服务，接受producer发送的half-message，然后给producer返回响应，如果producer没收到响应则重发。然后producer执行本地事务
接着根据本地事务的成功或失败发送commit/rollback给可靠消息服务。然后在可靠消息服务中启动一个后台线程定时扫描本地数据库表中所有的half-message，超过一定时间没有commit/rollback就回调producer
提供的接口来确认本地事务是否成功，来获取commit/rollback。如果消息被rollback就废弃掉，如果消息被commit就发送这个消息给下游服务，或者是发送给RabbitMQ/kafka/ActiveMQ
，然后下游服务消费了就必须回调可靠消息服务接口进行ack，如果一段时间都没有接收到ack则重发消息给下游服务

### 作业:如果对自己系统落地最终一致性，如何落地实现？
思路全给到位了，想想自己系统里哪个业务场景可以用这个分布式事务，基于RocketMQ实现一遍，再自己写可靠消息服务实现一遍


